#!/usr/bin/env python3
"""
Quant-Investor V6.0 - ç»Ÿä¸€æ¨¡å‹å±‚ (Unified Model Layer)

æ•´åˆV5.0çš„æœºå™¨å­¦ä¹ æ¨¡å‹èƒ½åŠ›ï¼š
- XGBoost / LightGBM / Random Forest
- æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ (é¿å…æ•°æ®æ³„éœ²)
- æ¨¡å‹è¯„ä¼°ä¸ç‰¹å¾é‡è¦æ€§åˆ†æ
- å¤šæ¨¡å‹é›†æˆä¸ä¿¡å·ç”Ÿæˆ
- å€™é€‰è‚¡ç¥¨æ’åºä¸ç­›é€‰

è®¾è®¡åŸåˆ™ï¼š
1. æ¨¡å‹è®­ç»ƒä¸¥æ ¼éµå¾ªæ—¶é—´åºåˆ—è§„åˆ™ï¼Œé˜²æ­¢å‰è§†åå·®
2. å¤šæ¨¡å‹é›†æˆï¼Œæé«˜ä¿¡å·ç¨³å®šæ€§
3. è¾“å‡ºæ ‡å‡†åŒ–çš„é¢„æµ‹ä¿¡å·å’Œå€™é€‰è‚¡ç¥¨æ’å
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class ModelResult:
    """å•ä¸ªæ¨¡å‹çš„è®­ç»ƒç»“æœ"""
    model_name: str
    train_score: float = 0.0
    test_score: float = 0.0
    mse: float = 0.0
    feature_importance: Dict[str, float] = field(default_factory=dict)
    predictions: pd.Series = None


@dataclass
class ModelLayerOutput:
    """æ¨¡å‹å±‚çš„å®Œæ•´è¾“å‡º"""
    # å„æ¨¡å‹ç»“æœ
    model_results: Dict[str, ModelResult] = field(default_factory=dict)
    
    # é›†æˆé¢„æµ‹ä¿¡å·
    ensemble_signal: pd.Series = None
    
    # æ’åºåçš„å€™é€‰è‚¡ç¥¨
    ranked_stocks: List[Dict[str, Any]] = field(default_factory=list)
    
    # ç‰¹å¾é‡è¦æ€§ (é›†æˆ)
    feature_importance: Dict[str, float] = field(default_factory=dict)
    
    # ç»Ÿè®¡æ‘˜è¦
    stats: Dict[str, Any] = field(default_factory=dict)


# ==================== æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ ====================

class TimeSeriesCV:
    """æ—¶é—´åºåˆ—äº¤å‰éªŒè¯å™¨ (æºè‡ªV5.0)"""
    
    def __init__(self, n_splits: int = 5, gap: int = 5):
        self.n_splits = n_splits
        self.gap = gap
    
    def split(self, X: pd.DataFrame) -> List[Tuple[np.ndarray, np.ndarray]]:
        n = len(X)
        test_size = n // (self.n_splits + 1)
        splits = []
        
        for i in range(self.n_splits):
            test_end = n - i * test_size
            test_start = test_end - test_size
            train_end = test_start - self.gap
            
            if train_end <= 0 or test_start >= test_end:
                continue
            
            train_idx = np.arange(0, train_end)
            test_idx = np.arange(test_start, test_end)
            splits.append((train_idx, test_idx))
        
        return splits[::-1]


# ==================== æ¨¡å‹åŒ…è£…å™¨ ====================

class XGBoostModel:
    """XGBoostæ¨¡å‹åŒ…è£…å™¨"""
    
    def __init__(self, **params):
        self.params = {
            'n_estimators': 200,
            'max_depth': 6,
            'learning_rate': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'reg_alpha': 0.1,
            'reg_lambda': 1.0,
            'random_state': 42,
            'n_jobs': -1,
        }
        self.params.update(params)
        self.model = None
    
    def fit(self, X, y):
        try:
            from xgboost import XGBRegressor
            self.model = XGBRegressor(**self.params)
            self.model.fit(X, y, verbose=False)
        except ImportError:
            # å›é€€åˆ°RandomForest
            self.model = RandomForestRegressor(
                n_estimators=200, max_depth=6, random_state=42, n_jobs=-1
            )
            self.model.fit(X, y)
        return self
    
    def predict(self, X):
        return self.model.predict(X)
    
    def feature_importances(self):
        if hasattr(self.model, 'feature_importances_'):
            return self.model.feature_importances_
        return None


class LightGBMModel:
    """LightGBMæ¨¡å‹åŒ…è£…å™¨"""
    
    def __init__(self, **params):
        self.params = {
            'n_estimators': 200,
            'max_depth': 6,
            'learning_rate': 0.05,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'reg_alpha': 0.1,
            'reg_lambda': 1.0,
            'random_state': 42,
            'n_jobs': -1,
            'verbose': -1,
        }
        self.params.update(params)
        self.model = None
    
    def fit(self, X, y):
        try:
            from lightgbm import LGBMRegressor
            self.model = LGBMRegressor(**self.params)
            self.model.fit(X, y)
        except ImportError:
            self.model = RandomForestRegressor(
                n_estimators=200, max_depth=6, random_state=42, n_jobs=-1
            )
            self.model.fit(X, y)
        return self
    
    def predict(self, X):
        return self.model.predict(X)
    
    def feature_importances(self):
        if hasattr(self.model, 'feature_importances_'):
            return self.model.feature_importances_
        return None


class RandomForestModel:
    """éšæœºæ£®æ—æ¨¡å‹åŒ…è£…å™¨"""
    
    def __init__(self, **params):
        self.params = {
            'n_estimators': 200,
            'max_depth': 8,
            'min_samples_split': 10,
            'min_samples_leaf': 5,
            'random_state': 42,
            'n_jobs': -1,
        }
        self.params.update(params)
        self.model = None
    
    def fit(self, X, y):
        self.model = RandomForestRegressor(**self.params)
        self.model.fit(X, y)
        return self
    
    def predict(self, X):
        return self.model.predict(X)
    
    def feature_importances(self):
        return self.model.feature_importances_


# ==================== ç»Ÿä¸€æ¨¡å‹å±‚ ====================

class UnifiedModelLayer:
    """
    V6.0 ç»Ÿä¸€æ¨¡å‹å±‚
    
    ä½¿ç”¨å¤šä¸ªMLæ¨¡å‹å¯¹å› å­è¿›è¡Œå»ºæ¨¡ï¼Œç”Ÿæˆé¢„æµ‹ä¿¡å·å’Œè‚¡ç¥¨æ’åã€‚
    """
    
    def __init__(self, verbose: bool = True, top_n_stocks: int = 10):
        self.verbose = verbose
        self.top_n_stocks = top_n_stocks
        self.models = {}
        self.scaler = StandardScaler()
    
    def predict(self, factor_matrix: pd.DataFrame, panel: pd.DataFrame,
                candidate_stocks: List[Dict] = None,
                stock_col: str = 'stock_code', date_col: str = 'date',
                target_col: str = 'returns', forward_periods: int = 5) -> ModelLayerOutput:
        """
        æ‰§è¡Œå®Œæ•´çš„æ¨¡å‹å±‚å¤„ç†
        
        Args:
            factor_matrix: å› å­çŸ©é˜µ (æ¥è‡ªå› å­å±‚)
            panel: åŸå§‹é¢æ¿æ•°æ®
            candidate_stocks: å€™é€‰è‚¡ç¥¨åˆ—è¡¨ (æ¥è‡ªå› å­å±‚)
            stock_col: è‚¡ç¥¨ä»£ç åˆ—å
            date_col: æ—¥æœŸåˆ—å
            target_col: ç›®æ ‡å˜é‡åˆ—å
            forward_periods: å‰ç»æœŸ
        
        Returns:
            ModelLayerOutput: æ¨¡å‹å±‚å®Œæ•´è¾“å‡º
        """
        output = ModelLayerOutput()
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ¤– V6.0 ç»Ÿä¸€æ¨¡å‹å±‚")
            print(f"{'='*60}")
        
        # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
        if self.verbose:
            print(f"\n  ğŸ“‹ å‡†å¤‡è®­ç»ƒæ•°æ®...")
        
        train_data = self._prepare_training_data(
            factor_matrix, panel, stock_col, date_col, target_col, forward_periods
        )
        
        if train_data is None:
            if self.verbose:
                print(f"    âš ï¸ è®­ç»ƒæ•°æ®ä¸è¶³ï¼Œè·³è¿‡æ¨¡å‹è®­ç»ƒ")
            # ç›´æ¥ä½¿ç”¨å› å­å±‚çš„å€™é€‰è‚¡ç¥¨
            output.ranked_stocks = candidate_stocks or []
            return output
        
        X_train, y_train, X_latest, feature_names, latest_stocks = train_data
        
        if self.verbose:
            print(f"    âœ“ è®­ç»ƒæ ·æœ¬: {len(X_train)}, ç‰¹å¾æ•°: {X_train.shape[1]}")
            print(f"    âœ“ é¢„æµ‹æ ·æœ¬: {len(X_latest)}")
        
        # 2. è®­ç»ƒå¤šä¸ªæ¨¡å‹
        model_configs = {
            'XGBoost': XGBoostModel(),
            'LightGBM': LightGBMModel(),
            'RandomForest': RandomForestModel(),
        }
        
        all_predictions = {}
        all_importances = {}
        
        for name, model in model_configs.items():
            if self.verbose:
                print(f"\n  ğŸ”§ è®­ç»ƒ {name}...")
            
            try:
                result = self._train_and_evaluate(
                    model, name, X_train, y_train, X_latest, feature_names
                )
                output.model_results[name] = result
                
                if result.predictions is not None:
                    all_predictions[name] = result.predictions
                
                if result.feature_importance:
                    all_importances[name] = result.feature_importance
                
                if self.verbose:
                    print(f"    âœ“ {name}: Train RÂ²={result.train_score:.4f}, "
                          f"Test RÂ²={result.test_score:.4f}")
            except Exception as e:
                if self.verbose:
                    print(f"    âœ— {name} è®­ç»ƒå¤±è´¥: {e}")
        
        # 3. é›†æˆé¢„æµ‹
        if all_predictions:
            pred_df = pd.DataFrame(all_predictions)
            output.ensemble_signal = pred_df.mean(axis=1)
            
            if self.verbose:
                print(f"\n  ğŸ”— é›†æˆé¢„æµ‹å®Œæˆ: {len(output.ensemble_signal)} åªè‚¡ç¥¨")
        
        # 4. é›†æˆç‰¹å¾é‡è¦æ€§
        if all_importances:
            combined = pd.DataFrame(all_importances)
            output.feature_importance = combined.mean(axis=1).sort_values(ascending=False).to_dict()
            
            if self.verbose:
                print(f"\n  ğŸ“Š Top 10 é‡è¦ç‰¹å¾:")
                for i, (feat, imp) in enumerate(list(output.feature_importance.items())[:10], 1):
                    print(f"    {i:2d}. {feat:<25s} importance={imp:.4f}")
        
        # 5. æ’åºå€™é€‰è‚¡ç¥¨
        output.ranked_stocks = self._rank_stocks(
            output.ensemble_signal, latest_stocks, candidate_stocks
        )
        
        # 6. ç»Ÿè®¡æ‘˜è¦
        output.stats = {
            "models_trained": len(output.model_results),
            "training_samples": len(X_train),
            "features_used": X_train.shape[1],
            "ranked_stocks": len(output.ranked_stocks),
            "best_model": max(output.model_results.items(), 
                            key=lambda x: x[1].test_score)[0] if output.model_results else "N/A",
        }
        
        if self.verbose:
            print(f"\n  âœ… æ¨¡å‹å±‚å¤„ç†å®Œæˆ")
            print(f"     è®­ç»ƒæ¨¡å‹: {output.stats['models_trained']} ä¸ª")
            print(f"     æœ€ä½³æ¨¡å‹: {output.stats['best_model']}")
            print(f"     æ’åºè‚¡ç¥¨: {output.stats['ranked_stocks']} åª")
        
        return output
    
    def _prepare_training_data(self, factor_matrix, panel, stock_col, date_col, 
                                target_col, forward_periods):
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        if factor_matrix is None or len(factor_matrix) == 0:
            return None
        
        # åˆå¹¶å› å­å’Œç›®æ ‡
        data = factor_matrix.copy()
        
        # ç¡®ä¿æœ‰ç›®æ ‡å˜é‡
        if target_col not in data.columns and target_col in panel.columns:
            # ä»panelä¸­åˆå¹¶
            merge_cols = [stock_col, date_col, target_col]
            merge_cols = [c for c in merge_cols if c in panel.columns]
            if len(merge_cols) >= 3:
                data = data.merge(panel[merge_cols], on=[stock_col, date_col], how='left')
        
        if target_col not in data.columns:
            # ä»Closeè®¡ç®—
            if 'Close' in data.columns:
                data[target_col] = data.groupby(stock_col)['Close'].pct_change()
            else:
                return None
        
        # è®¡ç®—å‰ç»æ”¶ç›Šç‡
        data['forward_return'] = data.groupby(stock_col)[target_col].shift(-forward_periods)
        
        # è¯†åˆ«ç‰¹å¾åˆ—
        exclude_cols = {stock_col, date_col, 'stock_name', 'industry', target_col, 
                       'forward_return', 'Open', 'High', 'Low', 'Close', 'Volume',
                       'log_returns', 'turnover'}
        feature_cols = [c for c in data.columns 
                       if c not in exclude_cols and data[c].dtype in ['float64', 'float32', 'int64']]
        
        if len(feature_cols) < 3:
            return None
        
        # åˆ†ç¦»è®­ç»ƒæ•°æ®å’Œæœ€æ–°æˆªé¢
        latest_date = data[date_col].max()
        
        # è®­ç»ƒæ•°æ®: æ’é™¤æœ€æ–°æ—¥æœŸï¼ˆæ²¡æœ‰å‰ç»æ”¶ç›Šï¼‰
        train_mask = (data[date_col] < latest_date) & data['forward_return'].notna()
        train_data = data[train_mask].copy()
        
        # æœ€æ–°æˆªé¢: ç”¨äºé¢„æµ‹
        latest_data = data[data[date_col] == latest_date].copy()
        
        if len(train_data) < 50 or len(latest_data) < 5:
            return None
        
        # å¤„ç†ç¼ºå¤±å€¼
        for col in feature_cols:
            train_data[col] = train_data[col].fillna(train_data[col].median())
            latest_data[col] = latest_data[col].fillna(latest_data[col].median())
        
        X_train = train_data[feature_cols].values
        y_train = train_data['forward_return'].values
        X_latest = latest_data[feature_cols].values
        latest_stocks = latest_data[stock_col].values
        
        # æ ‡å‡†åŒ–
        X_train = self.scaler.fit_transform(X_train)
        X_latest = self.scaler.transform(X_latest)
        
        # å¤„ç†NaN/Inf
        X_train = np.nan_to_num(X_train, nan=0, posinf=0, neginf=0)
        X_latest = np.nan_to_num(X_latest, nan=0, posinf=0, neginf=0)
        y_train = np.nan_to_num(y_train, nan=0, posinf=0, neginf=0)
        
        return X_train, y_train, X_latest, feature_cols, latest_stocks
    
    def _train_and_evaluate(self, model, name, X_train, y_train, X_latest, feature_names):
        """è®­ç»ƒå’Œè¯„ä¼°å•ä¸ªæ¨¡å‹"""
        result = ModelResult(model_name=name)
        
        # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        cv = TimeSeriesCV(n_splits=3, gap=5)
        splits = cv.split(pd.DataFrame(X_train))
        
        cv_scores = []
        for train_idx, test_idx in splits:
            X_tr, X_te = X_train[train_idx], X_train[test_idx]
            y_tr, y_te = y_train[train_idx], y_train[test_idx]
            
            model.fit(X_tr, y_tr)
            y_pred = model.predict(X_te)
            
            score = r2_score(y_te, y_pred) if len(y_te) > 1 else 0
            cv_scores.append(score)
        
        result.test_score = float(np.mean(cv_scores)) if cv_scores else 0
        
        # ä½¿ç”¨å…¨éƒ¨è®­ç»ƒæ•°æ®é‡æ–°è®­ç»ƒ
        model.fit(X_train, y_train)
        train_pred = model.predict(X_train)
        result.train_score = float(r2_score(y_train, train_pred))
        result.mse = float(mean_squared_error(y_train, train_pred))
        
        # é¢„æµ‹æœ€æ–°æˆªé¢
        latest_pred = model.predict(X_latest)
        result.predictions = pd.Series(latest_pred)
        
        # ç‰¹å¾é‡è¦æ€§
        importances = model.feature_importances()
        if importances is not None:
            result.feature_importance = {
                name: float(imp) for name, imp in zip(feature_names, importances)
            }
        
        return result
    
    def _rank_stocks(self, ensemble_signal, latest_stocks, candidate_stocks):
        """æ’åºå€™é€‰è‚¡ç¥¨"""
        if ensemble_signal is None or len(ensemble_signal) == 0:
            return candidate_stocks or []
        
        # åˆ›å»ºå€™é€‰è‚¡ç¥¨ä¿¡æ¯ç´¢å¼•
        candidate_info = {}
        if candidate_stocks:
            for s in candidate_stocks:
                candidate_info[s['code']] = s
        
        # æ’åº
        ranked = []
        signal_values = ensemble_signal.values
        
        # æŒ‰é¢„æµ‹ä¿¡å·æ’åº
        sorted_indices = np.argsort(-signal_values)
        
        for idx in sorted_indices[:self.top_n_stocks]:
            if idx < len(latest_stocks):
                code = latest_stocks[idx]
                info = candidate_info.get(code, {})
                
                ranked.append({
                    'code': code,
                    'name': info.get('name', code),
                    'ml_signal': float(signal_values[idx]),
                    'factor_score': info.get('composite_score', 0),
                    'combined_score': float(signal_values[idx]) * 0.6 + info.get('composite_score', 0) * 0.4,
                    'industry': info.get('industry', ''),
                    'latest_price': info.get('latest_price', 0),
                })
        
        # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
        ranked.sort(key=lambda x: x['combined_score'], reverse=True)
        
        return ranked


# ==================== ä¾¿æ·å‡½æ•° ====================

def run_model_prediction(factor_matrix: pd.DataFrame, panel: pd.DataFrame,
                          candidate_stocks: List[Dict] = None,
                          verbose: bool = True, top_n: int = 10) -> ModelLayerOutput:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œæ¨¡å‹é¢„æµ‹
    """
    layer = UnifiedModelLayer(verbose=verbose, top_n_stocks=top_n)
    return layer.predict(factor_matrix, panel, candidate_stocks)


if __name__ == "__main__":
    print("=" * 60)
    print("V6.0 ç»Ÿä¸€æ¨¡å‹å±‚æµ‹è¯•")
    print("=" * 60)
    print("æ¨¡å‹å±‚éœ€è¦å› å­å±‚çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œè¯·é€šè¿‡MasterPipelineè¿è¡Œå®Œæ•´æµç¨‹ã€‚")
