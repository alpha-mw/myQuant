#!/usr/bin/env python3
"""
Quant-Investor V6.0 - ç»Ÿä¸€ç»„åˆä¸é£æ§å±‚ (Unified Risk Layer)

æ•´åˆæ‰€æœ‰å†å²ç‰ˆæœ¬çš„ç»„åˆä¼˜åŒ–å’Œé£é™©ç®¡ç†èƒ½åŠ›ï¼š
- V4.1: Alpha/Beta/IR/èƒœç‡/ç‰›ç†Šå¸‚åˆ†æ
- V5.0: ç»„åˆä¼˜åŒ– (ç­‰æƒ/é£é™©å¹³ä»·/æœ€å¤§å¤æ™®/æœ€å°æ–¹å·®/Black-Litterman)
- V5.0: é£é™©ç®¡ç† (VaR/CVaR/å‹åŠ›æµ‹è¯•/å›æ’¤æ§åˆ¶/ä»“ä½ç®¡ç†)

è®¾è®¡åŸåˆ™ï¼š
1. ç»Ÿä¸€çš„ç»„åˆæ„å»ºæ¥å£
2. å¤šç»´åº¦é£é™©è¯„ä¼°
3. åŸºå‡†å¯¹æ¯”éªŒè¯
4. åŠ¨æ€ä»“ä½ç®¡ç†
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from scipy import optimize, stats
import warnings
warnings.filterwarnings('ignore')


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class PortfolioAllocation:
    """ç»„åˆé…ç½®"""
    weights: Dict[str, float] = field(default_factory=dict)
    method: str = ""
    expected_return: float = 0.0
    expected_volatility: float = 0.0
    sharpe_ratio: float = 0.0


@dataclass
class RiskMetrics:
    """é£é™©æŒ‡æ ‡"""
    # VaR/CVaR
    var_95: float = 0.0
    var_99: float = 0.0
    cvar_95: float = 0.0
    cvar_99: float = 0.0
    
    # æ³¢åŠ¨ç‡
    annual_volatility: float = 0.0
    downside_volatility: float = 0.0
    
    # å›æ’¤
    max_drawdown: float = 0.0
    avg_drawdown: float = 0.0
    max_drawdown_duration: int = 0
    
    # å°¾éƒ¨é£é™©
    skewness: float = 0.0
    kurtosis: float = 0.0
    tail_ratio: float = 0.0


@dataclass
class BenchmarkComparison:
    """åŸºå‡†å¯¹æ¯”ç»“æœ (æºè‡ªV4.1)"""
    # åŸºç¡€
    portfolio_return: float = 0.0
    benchmark_return: float = 0.0
    excess_return: float = 0.0
    
    # å¹´åŒ–
    annual_alpha: float = 0.0
    annual_portfolio: float = 0.0
    annual_benchmark: float = 0.0
    
    # é£é™©è°ƒæ•´
    beta: float = 0.0
    information_ratio: float = 0.0
    tracking_error: float = 0.0
    
    # èƒœç‡
    win_rate: float = 0.0
    up_capture: float = 0.0
    down_capture: float = 0.0
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§
    alpha_tstat: float = 0.0
    alpha_pvalue: float = 1.0
    is_significant: bool = False
    
    # ç‰›ç†Šå¸‚
    bull_alpha: float = 0.0
    bear_alpha: float = 0.0


@dataclass
class StressTestResult:
    """å‹åŠ›æµ‹è¯•ç»“æœ"""
    scenario_name: str
    portfolio_impact: float = 0.0
    benchmark_impact: float = 0.0
    worst_stock: str = ""
    worst_impact: float = 0.0


@dataclass
class RiskLayerOutput:
    """é£æ§å±‚å®Œæ•´è¾“å‡º"""
    # ç»„åˆé…ç½®
    portfolio: PortfolioAllocation = None
    alternative_portfolios: Dict[str, PortfolioAllocation] = field(default_factory=dict)
    
    # é£é™©æŒ‡æ ‡
    risk_metrics: RiskMetrics = None
    
    # åŸºå‡†å¯¹æ¯”
    benchmark_comparison: BenchmarkComparison = None
    
    # å‹åŠ›æµ‹è¯•
    stress_tests: List[StressTestResult] = field(default_factory=list)
    
    # ä»“ä½å»ºè®®
    position_sizing: Dict[str, Dict[str, Any]] = field(default_factory=dict)
    
    # é£é™©é¢„è­¦
    risk_alerts: List[str] = field(default_factory=list)
    
    # ç»Ÿè®¡
    stats: Dict[str, Any] = field(default_factory=dict)


# ==================== ç»„åˆä¼˜åŒ–å™¨ ====================

class PortfolioOptimizer:
    """
    ç»„åˆä¼˜åŒ–å™¨ (æºè‡ªV5.0)
    
    æ”¯æŒå¤šç§ä¼˜åŒ–æ–¹æ³•ï¼šç­‰æƒã€é£é™©å¹³ä»·ã€æœ€å¤§å¤æ™®ã€æœ€å°æ–¹å·®ã€‚
    """
    
    def __init__(self, risk_free_rate: float = 0.04):
        self.risk_free_rate = risk_free_rate
    
    def optimize(self, returns: pd.DataFrame, method: str = 'max_sharpe',
                  constraints: Dict = None) -> PortfolioAllocation:
        """
        ä¼˜åŒ–ç»„åˆæƒé‡
        
        Args:
            returns: å„è‚¡ç¥¨æ”¶ç›Šç‡DataFrame (åˆ—ä¸ºè‚¡ç¥¨ä»£ç )
            method: ä¼˜åŒ–æ–¹æ³•
            constraints: çº¦æŸæ¡ä»¶
        
        Returns:
            PortfolioAllocation: ç»„åˆé…ç½®
        """
        if method == 'equal_weight':
            return self._equal_weight(returns)
        elif method == 'risk_parity':
            return self._risk_parity(returns)
        elif method == 'max_sharpe':
            return self._max_sharpe(returns, constraints)
        elif method == 'min_variance':
            return self._min_variance(returns, constraints)
        else:
            return self._equal_weight(returns)
    
    def _equal_weight(self, returns: pd.DataFrame) -> PortfolioAllocation:
        """ç­‰æƒé…ç½®"""
        n = len(returns.columns)
        weights = {col: 1.0/n for col in returns.columns}
        return self._build_allocation(weights, returns, "ç­‰æƒé…ç½®")
    
    def _risk_parity(self, returns: pd.DataFrame) -> PortfolioAllocation:
        """é£é™©å¹³ä»·"""
        cov = returns.cov() * 252
        n = len(returns.columns)
        
        def risk_budget_objective(w):
            port_vol = np.sqrt(w @ cov.values @ w)
            marginal_risk = cov.values @ w / port_vol
            risk_contrib = w * marginal_risk
            target = port_vol / n
            return np.sum((risk_contrib - target) ** 2)
        
        w0 = np.ones(n) / n
        bounds = [(0.01, 0.5)] * n
        constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
        
        try:
            result = optimize.minimize(risk_budget_objective, w0, method='SLSQP',
                                       bounds=bounds, constraints=constraints)
            weights = {col: float(w) for col, w in zip(returns.columns, result.x)}
        except:
            weights = {col: 1.0/n for col in returns.columns}
        
        return self._build_allocation(weights, returns, "é£é™©å¹³ä»·")
    
    def _max_sharpe(self, returns: pd.DataFrame, constraints: Dict = None) -> PortfolioAllocation:
        """æœ€å¤§å¤æ™®æ¯”ç‡"""
        mean_returns = returns.mean() * 252
        cov = returns.cov() * 252
        n = len(returns.columns)
        
        def neg_sharpe(w):
            port_ret = w @ mean_returns.values
            port_vol = np.sqrt(w @ cov.values @ w)
            return -(port_ret - self.risk_free_rate) / (port_vol + 1e-8)
        
        w0 = np.ones(n) / n
        max_weight = (constraints or {}).get('max_weight', 0.3)
        bounds = [(0.0, max_weight)] * n
        cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
        
        try:
            result = optimize.minimize(neg_sharpe, w0, method='SLSQP',
                                       bounds=bounds, constraints=cons)
            weights = {col: max(0, float(w)) for col, w in zip(returns.columns, result.x)}
            # å½’ä¸€åŒ–
            total = sum(weights.values())
            if total > 0:
                weights = {k: v/total for k, v in weights.items()}
        except:
            weights = {col: 1.0/n for col in returns.columns}
        
        return self._build_allocation(weights, returns, "æœ€å¤§å¤æ™®")
    
    def _min_variance(self, returns: pd.DataFrame, constraints: Dict = None) -> PortfolioAllocation:
        """æœ€å°æ–¹å·®"""
        cov = returns.cov() * 252
        n = len(returns.columns)
        
        def portfolio_variance(w):
            return w @ cov.values @ w
        
        w0 = np.ones(n) / n
        max_weight = (constraints or {}).get('max_weight', 0.3)
        bounds = [(0.0, max_weight)] * n
        cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
        
        try:
            result = optimize.minimize(portfolio_variance, w0, method='SLSQP',
                                       bounds=bounds, constraints=cons)
            weights = {col: max(0, float(w)) for col, w in zip(returns.columns, result.x)}
            total = sum(weights.values())
            if total > 0:
                weights = {k: v/total for k, v in weights.items()}
        except:
            weights = {col: 1.0/n for col in returns.columns}
        
        return self._build_allocation(weights, returns, "æœ€å°æ–¹å·®")
    
    def _build_allocation(self, weights: Dict[str, float], returns: pd.DataFrame,
                           method: str) -> PortfolioAllocation:
        """æ„å»ºç»„åˆé…ç½®"""
        w = np.array([weights.get(col, 0) for col in returns.columns])
        mean_ret = returns.mean().values * 252
        cov = returns.cov().values * 252
        
        exp_ret = float(w @ mean_ret)
        exp_vol = float(np.sqrt(w @ cov @ w))
        sharpe = (exp_ret - self.risk_free_rate) / (exp_vol + 1e-8)
        
        return PortfolioAllocation(
            weights=weights, method=method,
            expected_return=exp_ret, expected_volatility=exp_vol,
            sharpe_ratio=float(sharpe)
        )


# ==================== é£é™©ç®¡ç†å™¨ ====================

class RiskManager:
    """
    é£é™©ç®¡ç†å™¨ (æºè‡ªV5.0)
    
    æä¾›VaR/CVaRã€å‹åŠ›æµ‹è¯•ã€å›æ’¤åˆ†æç­‰é£é™©è¯„ä¼°å·¥å…·ã€‚
    """
    
    def __init__(self, risk_free_rate: float = 0.04):
        self.risk_free_rate = risk_free_rate
    
    def calculate_risk_metrics(self, portfolio_returns: pd.Series) -> RiskMetrics:
        """è®¡ç®—å®Œæ•´çš„é£é™©æŒ‡æ ‡"""
        metrics = RiskMetrics()
        
        if len(portfolio_returns) < 10:
            return metrics
        
        returns = portfolio_returns.dropna()
        
        # VaR/CVaR
        metrics.var_95 = float(np.percentile(returns, 5))
        metrics.var_99 = float(np.percentile(returns, 1))
        metrics.cvar_95 = float(returns[returns <= metrics.var_95].mean()) if (returns <= metrics.var_95).any() else metrics.var_95
        metrics.cvar_99 = float(returns[returns <= metrics.var_99].mean()) if (returns <= metrics.var_99).any() else metrics.var_99
        
        # æ³¢åŠ¨ç‡
        metrics.annual_volatility = float(returns.std() * np.sqrt(252))
        metrics.downside_volatility = float(returns[returns < 0].std() * np.sqrt(252)) if (returns < 0).any() else 0
        
        # å›æ’¤
        cum_returns = (1 + returns).cumprod()
        peak = cum_returns.expanding().max()
        drawdown = (cum_returns - peak) / peak
        metrics.max_drawdown = float(drawdown.min())
        metrics.avg_drawdown = float(drawdown[drawdown < 0].mean()) if (drawdown < 0).any() else 0
        
        # æœ€å¤§å›æ’¤æŒç»­æ—¶é—´
        is_drawdown = drawdown < 0
        if is_drawdown.any():
            dd_groups = (~is_drawdown).cumsum()
            dd_lengths = is_drawdown.groupby(dd_groups).sum()
            metrics.max_drawdown_duration = int(dd_lengths.max()) if len(dd_lengths) > 0 else 0
        
        # é«˜é˜¶ç»Ÿè®¡
        metrics.skewness = float(returns.skew())
        metrics.kurtosis = float(returns.kurtosis())
        
        # å°¾éƒ¨æ¯”ç‡
        upper_tail = returns[returns > 0].quantile(0.95) if (returns > 0).any() else 0
        lower_tail = abs(returns[returns < 0].quantile(0.05)) if (returns < 0).any() else 1
        metrics.tail_ratio = float(upper_tail / (lower_tail + 1e-8))
        
        return metrics
    
    def benchmark_comparison(self, portfolio_returns: pd.Series,
                              benchmark_returns: pd.Series) -> BenchmarkComparison:
        """åŸºå‡†å¯¹æ¯”åˆ†æ (æºè‡ªV4.1)"""
        comp = BenchmarkComparison()
        
        # å¯¹é½æ•°æ®
        aligned = pd.DataFrame({
            'portfolio': portfolio_returns,
            'benchmark': benchmark_returns
        }).dropna()
        
        if len(aligned) < 20:
            return comp
        
        pr = aligned['portfolio']
        br = aligned['benchmark']
        excess = pr - br
        n_days = len(aligned)
        
        # åŸºç¡€æ”¶ç›Š
        comp.portfolio_return = float((1 + pr).prod() - 1)
        comp.benchmark_return = float((1 + br).prod() - 1)
        comp.excess_return = comp.portfolio_return - comp.benchmark_return
        
        # å¹´åŒ–
        years = n_days / 252
        comp.annual_portfolio = float((1 + comp.portfolio_return) ** (1/years) - 1) if years > 0 else 0
        comp.annual_benchmark = float((1 + comp.benchmark_return) ** (1/years) - 1) if years > 0 else 0
        comp.annual_alpha = comp.annual_portfolio - comp.annual_benchmark
        
        # Beta
        cov_matrix = np.cov(pr.values, br.values)
        comp.beta = float(cov_matrix[0, 1] / (cov_matrix[1, 1] + 1e-8))
        
        # Tracking Error & IR
        comp.tracking_error = float(excess.std() * np.sqrt(252))
        comp.information_ratio = float(excess.mean() * 252 / (comp.tracking_error + 1e-8))
        
        # èƒœç‡
        comp.win_rate = float((excess > 0).mean())
        
        # ä¸Šæ¶¨/ä¸‹è·Œæ•è·ç‡
        up_days = br > 0
        down_days = br < 0
        if up_days.sum() > 0:
            comp.up_capture = float(pr[up_days].mean() / (br[up_days].mean() + 1e-8))
        if down_days.sum() > 0:
            comp.down_capture = float(pr[down_days].mean() / (br[down_days].mean() + 1e-8))
        
        # Alphaæ˜¾è‘—æ€§æ£€éªŒ
        if len(excess) > 10:
            t_stat, p_value = stats.ttest_1samp(excess.values, 0)
            comp.alpha_tstat = float(t_stat)
            comp.alpha_pvalue = float(p_value)
            comp.is_significant = p_value < 0.05
        
        # ç‰›ç†Šå¸‚åˆ†æ
        bull_mask = br.rolling(60).mean() > 0
        bear_mask = ~bull_mask
        
        if bull_mask.sum() > 10:
            comp.bull_alpha = float((excess[bull_mask].mean()) * 252)
        if bear_mask.sum() > 10:
            comp.bear_alpha = float((excess[bear_mask].mean()) * 252)
        
        return comp
    
    def stress_test(self, returns: pd.DataFrame, weights: Dict[str, float]) -> List[StressTestResult]:
        """å‹åŠ›æµ‹è¯•"""
        scenarios = {
            "å¸‚åœºæš´è·Œ (-20%)": {"market_shock": -0.20},
            "åˆ©ç‡é£™å‡ (+200bp)": {"market_shock": -0.10, "vol_multiplier": 1.5},
            "æµåŠ¨æ€§å±æœº": {"market_shock": -0.15, "vol_multiplier": 2.0},
            "ç§‘æŠ€è‚¡å´©ç›˜ (-30%)": {"market_shock": -0.30},
            "æ¸©å’Œå›è°ƒ (-10%)": {"market_shock": -0.10},
        }
        
        results = []
        for name, params in scenarios.items():
            shock = params.get('market_shock', -0.10)
            vol_mult = params.get('vol_multiplier', 1.0)
            
            # æ¨¡æ‹Ÿå„è‚¡ç¥¨åœ¨å‹åŠ›åœºæ™¯ä¸‹çš„è¡¨ç°
            stock_impacts = {}
            portfolio_impact = 0.0
            worst_stock = ""
            worst_impact = 0.0
            
            for stock, weight in weights.items():
                if stock in returns.columns:
                    stock_vol = returns[stock].std() * np.sqrt(252)
                    beta_approx = returns[stock].corr(returns.mean(axis=1))
                    
                    impact = shock * beta_approx * vol_mult
                    stock_impacts[stock] = impact
                    portfolio_impact += weight * impact
                    
                    if impact < worst_impact:
                        worst_impact = impact
                        worst_stock = stock
            
            results.append(StressTestResult(
                scenario_name=name,
                portfolio_impact=float(portfolio_impact),
                benchmark_impact=float(shock),
                worst_stock=worst_stock,
                worst_impact=float(worst_impact)
            ))
        
        return results
    
    def position_sizing(self, weights: Dict[str, float], risk_metrics: RiskMetrics,
                         total_capital: float = 1000000,
                         max_position_pct: float = 0.20,
                         max_portfolio_var: float = 0.02) -> Dict[str, Dict[str, Any]]:
        """ä»“ä½ç®¡ç†"""
        positions = {}
        
        # åŸºäºé£é™©é¢„ç®—è°ƒæ•´ä»“ä½
        risk_budget = max_portfolio_var
        current_risk = abs(risk_metrics.var_95) if risk_metrics.var_95 else 0.02
        
        # é£é™©è°ƒæ•´ç³»æ•°
        risk_adj = min(1.0, risk_budget / (current_risk + 1e-8))
        
        for stock, weight in weights.items():
            adjusted_weight = min(weight * risk_adj, max_position_pct)
            capital_allocated = total_capital * adjusted_weight
            
            positions[stock] = {
                'target_weight': float(adjusted_weight),
                'capital_allocated': float(capital_allocated),
                'original_weight': float(weight),
                'risk_adjusted': risk_adj < 1.0,
            }
        
        return positions


# ==================== ç»Ÿä¸€é£æ§å±‚ ====================

class UnifiedRiskLayer:
    """
    V6.0 ç»Ÿä¸€ç»„åˆä¸é£æ§å±‚
    
    æ•´åˆç»„åˆä¼˜åŒ–ã€é£é™©è¯„ä¼°ã€åŸºå‡†å¯¹æ¯”å’Œä»“ä½ç®¡ç†ã€‚
    """
    
    def __init__(self, risk_free_rate: float = 0.04, verbose: bool = True):
        self.verbose = verbose
        self.optimizer = PortfolioOptimizer(risk_free_rate=risk_free_rate)
        self.risk_manager = RiskManager(risk_free_rate=risk_free_rate)
    
    def process(self, recommendations: List[Dict], data_bundle=None,
                optimization_method: str = 'max_sharpe',
                total_capital: float = 1000000) -> RiskLayerOutput:
        """
        æ‰§è¡Œå®Œæ•´çš„ç»„åˆæ„å»ºå’Œé£é™©è¯„ä¼°
        
        Args:
            recommendations: æ¨èè‚¡ç¥¨åˆ—è¡¨ (æ¥è‡ªå†³ç­–å±‚)
            data_bundle: æ•°æ®åŒ… (æ¥è‡ªæ•°æ®å±‚)
            optimization_method: ä¼˜åŒ–æ–¹æ³•
            total_capital: æ€»èµ„é‡‘
        
        Returns:
            RiskLayerOutput: é£æ§å±‚å®Œæ•´è¾“å‡º
        """
        output = RiskLayerOutput()
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ›¡ï¸ V6.0 ç»Ÿä¸€ç»„åˆä¸é£æ§å±‚")
            print(f"{'='*60}")
        
        # 1. æå–æ¨èè‚¡ç¥¨çš„æ”¶ç›Šç‡æ•°æ®
        stock_codes = [r['code'] for r in recommendations if r.get('code')]
        returns_df = self._extract_returns(stock_codes, data_bundle)
        
        if returns_df is None or returns_df.empty:
            if self.verbose:
                print(f"  âš ï¸ æ— æ³•è·å–æ”¶ç›Šç‡æ•°æ®ï¼Œä½¿ç”¨ç­‰æƒé…ç½®")
            n = len(stock_codes)
            weights = {code: 1.0/n for code in stock_codes} if n > 0 else {}
            output.portfolio = PortfolioAllocation(weights=weights, method="ç­‰æƒé…ç½®(é»˜è®¤)")
            output.final_recommendations_with_weights = recommendations
            return output
        
        # 2. ç»„åˆä¼˜åŒ–
        if self.verbose:
            print(f"\n  ğŸ“Š ç»„åˆä¼˜åŒ– (æ–¹æ³•: {optimization_method})")
        
        output.portfolio = self.optimizer.optimize(returns_df, method=optimization_method)
        
        # ä¹Ÿè®¡ç®—å…¶ä»–æ–¹æ³•ä½œä¸ºå‚è€ƒ
        for method in ['equal_weight', 'risk_parity', 'min_variance']:
            if method != optimization_method:
                output.alternative_portfolios[method] = self.optimizer.optimize(returns_df, method=method)
        
        if self.verbose:
            print(f"    âœ“ ä¸»ç»„åˆ: {output.portfolio.method}")
            print(f"      é¢„æœŸæ”¶ç›Š: {output.portfolio.expected_return:.2%}")
            print(f"      é¢„æœŸæ³¢åŠ¨: {output.portfolio.expected_volatility:.2%}")
            print(f"      å¤æ™®æ¯”ç‡: {output.portfolio.sharpe_ratio:.2f}")
            print(f"\n    æƒé‡åˆ†é…:")
            for stock, weight in sorted(output.portfolio.weights.items(), key=lambda x: -x[1]):
                if weight > 0.001:
                    print(f"      {stock:<10s}: {weight:.1%}")
        
        # 3. è®¡ç®—ç»„åˆæ”¶ç›Šç‡
        w = np.array([output.portfolio.weights.get(col, 0) for col in returns_df.columns])
        portfolio_returns = (returns_df * w).sum(axis=1)
        
        # 4. é£é™©æŒ‡æ ‡
        if self.verbose:
            print(f"\n  ğŸ“‰ é£é™©è¯„ä¼°")
        
        output.risk_metrics = self.risk_manager.calculate_risk_metrics(portfolio_returns)
        
        if self.verbose:
            rm = output.risk_metrics
            print(f"    VaR (95%): {rm.var_95:.2%}")
            print(f"    CVaR (95%): {rm.cvar_95:.2%}")
            print(f"    å¹´åŒ–æ³¢åŠ¨ç‡: {rm.annual_volatility:.2%}")
            print(f"    æœ€å¤§å›æ’¤: {rm.max_drawdown:.2%}")
            print(f"    ååº¦: {rm.skewness:.2f}")
            print(f"    å³°åº¦: {rm.kurtosis:.2f}")
        
        # 5. åŸºå‡†å¯¹æ¯”
        benchmark_returns = self._get_benchmark_returns(data_bundle)
        if benchmark_returns is not None:
            if self.verbose:
                print(f"\n  ğŸ“Š åŸºå‡†å¯¹æ¯”")
            
            output.benchmark_comparison = self.risk_manager.benchmark_comparison(
                portfolio_returns, benchmark_returns
            )
            
            bc = output.benchmark_comparison
            if self.verbose:
                print(f"    å¹´åŒ–Alpha: {bc.annual_alpha:.2%}")
                print(f"    Beta: {bc.beta:.2f}")
                print(f"    ä¿¡æ¯æ¯”ç‡: {bc.information_ratio:.2f}")
                print(f"    èƒœç‡: {bc.win_rate:.1%}")
                print(f"    Alphaæ˜¾è‘—: {'âœ“' if bc.is_significant else 'âœ—'} (p={bc.alpha_pvalue:.4f})")
        
        # 6. å‹åŠ›æµ‹è¯•
        if self.verbose:
            print(f"\n  ğŸ”¥ å‹åŠ›æµ‹è¯•")
        
        output.stress_tests = self.risk_manager.stress_test(returns_df, output.portfolio.weights)
        
        if self.verbose:
            for st in output.stress_tests:
                print(f"    {st.scenario_name}: ç»„åˆå½±å“ {st.portfolio_impact:.2%}")
        
        # 7. ä»“ä½ç®¡ç†
        output.position_sizing = self.risk_manager.position_sizing(
            output.portfolio.weights, output.risk_metrics, total_capital
        )
        
        # 8. é£é™©é¢„è­¦
        output.risk_alerts = self._generate_alerts(output)
        
        if output.risk_alerts and self.verbose:
            print(f"\n  âš ï¸ é£é™©é¢„è­¦:")
            for alert in output.risk_alerts:
                print(f"    â€¢ {alert}")
        
        # 9. ç»Ÿè®¡
        output.stats = {
            "stocks_in_portfolio": sum(1 for w in output.portfolio.weights.values() if w > 0.001),
            "optimization_method": output.portfolio.method,
            "expected_return": output.portfolio.expected_return,
            "expected_volatility": output.portfolio.expected_volatility,
            "sharpe_ratio": output.portfolio.sharpe_ratio,
            "max_drawdown": output.risk_metrics.max_drawdown if output.risk_metrics else 0,
            "risk_alerts": len(output.risk_alerts),
        }
        
        if self.verbose:
            print(f"\n  âœ… é£æ§å±‚å¤„ç†å®Œæˆ")
        
        return output
    
    def _extract_returns(self, stock_codes: List[str], data_bundle) -> Optional[pd.DataFrame]:
        """ä»æ•°æ®åŒ…ä¸­æå–æ”¶ç›Šç‡"""
        if data_bundle is None or not hasattr(data_bundle, 'stock_universe'):
            return None
        
        returns_dict = {}
        for code in stock_codes:
            stock = data_bundle.stock_universe.get(code)
            if stock and stock.price_data is not None and len(stock.price_data) > 20:
                returns_dict[code] = stock.price_data['Close'].pct_change().dropna()
        
        if not returns_dict:
            return None
        
        returns_df = pd.DataFrame(returns_dict).dropna()
        return returns_df if len(returns_df) > 20 else None
    
    def _get_benchmark_returns(self, data_bundle) -> Optional[pd.Series]:
        """è·å–åŸºå‡†æ”¶ç›Šç‡"""
        if data_bundle is None or data_bundle.benchmark_data is None:
            return None
        
        if 'Close' in data_bundle.benchmark_data.columns:
            return data_bundle.benchmark_data['Close'].pct_change().dropna()
        return None
    
    def _generate_alerts(self, output: RiskLayerOutput) -> List[str]:
        """ç”Ÿæˆé£é™©é¢„è­¦"""
        alerts = []
        
        if output.risk_metrics:
            rm = output.risk_metrics
            if rm.max_drawdown < -0.20:
                alerts.append(f"å†å²æœ€å¤§å›æ’¤è¾ƒå¤§ ({rm.max_drawdown:.1%})ï¼Œæ³¨æ„ä¸‹è¡Œé£é™©")
            if rm.annual_volatility > 0.30:
                alerts.append(f"å¹´åŒ–æ³¢åŠ¨ç‡è¾ƒé«˜ ({rm.annual_volatility:.1%})ï¼Œå»ºè®®é™ä½ä»“ä½")
            if rm.kurtosis > 3:
                alerts.append(f"æ”¶ç›Šåˆ†å¸ƒåšå°¾ (å³°åº¦={rm.kurtosis:.1f})ï¼Œå°¾éƒ¨é£é™©è¾ƒé«˜")
            if rm.skewness < -0.5:
                alerts.append(f"æ”¶ç›Šåˆ†å¸ƒå·¦å (ååº¦={rm.skewness:.2f})ï¼Œä¸‹è¡Œé£é™©ä¸å¯¹ç§°")
        
        if output.benchmark_comparison:
            bc = output.benchmark_comparison
            if bc.beta > 1.3:
                alerts.append(f"ç»„åˆBetaè¾ƒé«˜ ({bc.beta:.2f})ï¼Œå¸‚åœºä¸‹è·Œæ—¶æŸå¤±æ”¾å¤§")
            if bc.information_ratio < 0:
                alerts.append(f"ä¿¡æ¯æ¯”ç‡ä¸ºè´Ÿ ({bc.information_ratio:.2f})ï¼Œè¶…é¢æ”¶ç›Šä¸ç¨³å®š")
        
        # é›†ä¸­åº¦é£é™©
        if output.portfolio:
            max_weight = max(output.portfolio.weights.values()) if output.portfolio.weights else 0
            if max_weight > 0.25:
                alerts.append(f"æœ€å¤§å•ä¸€æŒä»“æƒé‡ {max_weight:.1%}ï¼Œé›†ä¸­åº¦é£é™©è¾ƒé«˜")
        
        # å‹åŠ›æµ‹è¯•
        for st in output.stress_tests:
            if st.portfolio_impact < -0.15:
                alerts.append(f"å‹åŠ›åœºæ™¯'{st.scenario_name}'ä¸‹ç»„åˆæŸå¤± {st.portfolio_impact:.1%}")
        
        return alerts


# ==================== ä¾¿æ·å‡½æ•° ====================

def run_risk_analysis(recommendations: List[Dict], data_bundle=None,
                       method: str = 'max_sharpe', capital: float = 1000000,
                       verbose: bool = True) -> RiskLayerOutput:
    """ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œç»„åˆä¼˜åŒ–å’Œé£é™©åˆ†æ"""
    layer = UnifiedRiskLayer(verbose=verbose)
    return layer.process(recommendations, data_bundle, method, capital)


if __name__ == "__main__":
    print("=" * 60)
    print("V6.0 ç»Ÿä¸€ç»„åˆä¸é£æ§å±‚æµ‹è¯•")
    print("=" * 60)
    print("é£æ§å±‚éœ€è¦å†³ç­–å±‚çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œè¯·é€šè¿‡MasterPipelineè¿è¡Œå®Œæ•´æµç¨‹ã€‚")
