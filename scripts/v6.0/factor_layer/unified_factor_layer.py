#!/usr/bin/env python3
"""
Quant-Investor V6.0 - ç»Ÿä¸€å› å­å±‚ (Unified Factor Layer)

æ•´åˆæ‰€æœ‰å†å²ç‰ˆæœ¬çš„å› å­èƒ½åŠ›ï¼š
- V3.2: é—ä¼ è§„åˆ’å› å­æŒ–æ˜å¼•æ“
- V3.3: å·¥ä¸šçº§å› å­åˆ†æ (Tear Sheet / IC / IR)
- V3.4: Alpha158å› å­åº“ + tsfreshç‰¹å¾
- V3.5: æ·±åº¦ç‰¹å¾åˆæˆå¼•æ“
- V4.1: åŸºå‡†å¯¹æ¯”éªŒè¯ (Alpha / Beta / IR / èƒœç‡)
- V5.0: 500+å› å­åº“ (åŸºæœ¬é¢/ä»·é‡/å®è§‚)

è®¾è®¡åŸåˆ™ï¼š
1. ç»Ÿä¸€çš„å› å­è®¡ç®—æ¥å£
2. è‡ªåŠ¨åŒ–çš„å› å­æœ‰æ•ˆæ€§æ£€éªŒ (IC/IR/åˆ†å±‚å›æµ‹)
3. åŸºäºåŸºå‡†çš„AlphaéªŒè¯
4. æ”¯æŒè‡ªå®šä¹‰å› å­æ³¨å†Œ
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass, field
from scipy import stats
import warnings
warnings.filterwarnings('ignore')


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class FactorResult:
    """å•ä¸ªå› å­çš„è®¡ç®—å’ŒéªŒè¯ç»“æœ"""
    name: str
    category: str
    description: str
    
    # å› å­å€¼
    values: pd.Series = None
    
    # ICåˆ†æ
    ic_mean: float = 0.0
    ic_std: float = 0.0
    ir: float = 0.0  # Information Ratio = IC_mean / IC_std
    ic_series: pd.Series = None
    
    # åˆ†å±‚å›æµ‹
    top_return: float = 0.0
    bottom_return: float = 0.0
    long_short_return: float = 0.0
    
    # åŸºå‡†å¯¹æ¯”
    alpha_vs_benchmark: float = 0.0
    win_rate_vs_benchmark: float = 0.0
    
    # æœ‰æ•ˆæ€§åˆ¤å®š
    is_effective: bool = False
    effectiveness_score: float = 0.0
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§
    ic_tstat: float = 0.0
    ic_pvalue: float = 1.0


@dataclass
class FactorLayerOutput:
    """å› å­å±‚çš„å®Œæ•´è¾“å‡º"""
    # æ‰€æœ‰è®¡ç®—çš„å› å­
    all_factors: Dict[str, FactorResult] = field(default_factory=dict)
    
    # æœ‰æ•ˆå› å­ï¼ˆé€šè¿‡ç­›é€‰çš„ï¼‰
    effective_factors: List[FactorResult] = field(default_factory=list)
    
    # å› å­çŸ©é˜µ (ç”¨äºæ¨¡å‹å±‚)
    factor_matrix: pd.DataFrame = None
    
    # å› å­ç›¸å…³æ€§çŸ©é˜µ
    correlation_matrix: pd.DataFrame = None
    
    # å€™é€‰è‚¡ç¥¨æ±  (å› å­ç»¼åˆæ’åTop N)
    candidate_stocks: List[Dict[str, Any]] = field(default_factory=list)
    
    # ç»Ÿè®¡æ‘˜è¦
    stats: Dict[str, Any] = field(default_factory=dict)


# ==================== å› å­è®¡ç®—å™¨ ====================

class FactorCalculator:
    """
    ç»Ÿä¸€å› å­è®¡ç®—å™¨
    
    æ•´åˆV3.4 Alpha158 + V5.0 500+å› å­åº“ï¼Œæä¾›å®Œæ•´çš„å› å­è®¡ç®—èƒ½åŠ›ã€‚
    """
    
    def __init__(self):
        self._custom_factors = {}
    
    def register_factor(self, name: str, category: str, description: str,
                         func: Callable[[pd.DataFrame], pd.Series]):
        """æ³¨å†Œè‡ªå®šä¹‰å› å­"""
        self._custom_factors[name] = {
            'category': category, 'description': description, 'func': func
        }
    
    def calculate_all(self, panel: pd.DataFrame, stock_col: str = 'stock_code',
                       date_col: str = 'date') -> pd.DataFrame:
        """
        è®¡ç®—æ‰€æœ‰å› å­
        
        Args:
            panel: é¢æ¿æ•°æ® (åŒ…å« Open/High/Low/Close/Volume ç­‰åˆ—)
            stock_col: è‚¡ç¥¨ä»£ç åˆ—å
            date_col: æ—¥æœŸåˆ—å
        
        Returns:
            åŒ…å«æ‰€æœ‰å› å­å€¼çš„DataFrame
        """
        result = panel.copy()
        
        # æŒ‰è‚¡ç¥¨åˆ†ç»„è®¡ç®—å› å­
        grouped = result.groupby(stock_col)
        
        # ===== ä»·é‡å› å­ =====
        # åŠ¨é‡å› å­
        for period in [5, 10, 20, 60, 120, 252]:
            col_name = f'momentum_{period}d'
            result[col_name] = grouped['Close'].pct_change(period)
        
        # åè½¬å› å­
        for period in [5, 10, 20]:
            col_name = f'reversal_{period}d'
            result[col_name] = -grouped['Close'].pct_change(period)
        
        # æ³¢åŠ¨ç‡å› å­
        for period in [10, 20, 60]:
            col_name = f'volatility_{period}d'
            result[col_name] = grouped['returns'].transform(
                lambda x: x.rolling(period, min_periods=max(5, period//2)).std() * np.sqrt(252)
            )
        
        # æˆäº¤é‡å› å­
        result['volume_ratio_5d'] = grouped['Volume'].transform(
            lambda x: x / x.rolling(5, min_periods=3).mean()
        )
        result['volume_ratio_20d'] = grouped['Volume'].transform(
            lambda x: x / x.rolling(20, min_periods=10).mean()
        )
        result['volume_std_20d'] = grouped['Volume'].transform(
            lambda x: x.rolling(20, min_periods=10).std() / (x.rolling(20, min_periods=10).mean() + 1e-8)
        )
        
        # ä»·æ ¼ä½ç½®å› å­
        result['price_position_20d'] = grouped['Close'].transform(
            lambda x: (x - x.rolling(20, min_periods=10).min()) / 
                      (x.rolling(20, min_periods=10).max() - x.rolling(20, min_periods=10).min() + 1e-8)
        )
        result['price_position_60d'] = grouped['Close'].transform(
            lambda x: (x - x.rolling(60, min_periods=30).min()) / 
                      (x.rolling(60, min_periods=30).max() - x.rolling(60, min_periods=30).min() + 1e-8)
        )
        
        # å‡çº¿åç¦»å› å­
        for period in [5, 10, 20, 60]:
            ma = grouped['Close'].transform(lambda x: x.rolling(period, min_periods=max(3, period//2)).mean())
            result[f'ma_bias_{period}d'] = (result['Close'] - ma) / (ma + 1e-8)
        
        # MACDç›¸å…³
        result['ema_12'] = grouped['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())
        result['ema_26'] = grouped['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())
        result['macd'] = result['ema_12'] - result['ema_26']
        result['macd_signal'] = grouped['macd'].transform(lambda x: x.ewm(span=9, adjust=False).mean())
        result['macd_hist'] = result['macd'] - result['macd_signal']
        
        # RSI
        for period in [6, 14, 24]:
            delta = grouped['Close'].diff()
            gain = delta.clip(lower=0)
            loss = (-delta).clip(lower=0)
            avg_gain = grouped[gain.name].transform(lambda x: x.rolling(period, min_periods=period//2).mean()) if gain.name in result.columns else gain.rolling(period, min_periods=period//2).mean()
            avg_loss = grouped[loss.name].transform(lambda x: x.rolling(period, min_periods=period//2).mean()) if loss.name in result.columns else loss.rolling(period, min_periods=period//2).mean()
            # Simplified RSI calculation
            result[f'rsi_{period}'] = 100 - (100 / (1 + avg_gain / (avg_loss + 1e-8)))
        
        # å¸ƒæ—å¸¦
        result['bb_mid'] = grouped['Close'].transform(lambda x: x.rolling(20, min_periods=10).mean())
        bb_std = grouped['Close'].transform(lambda x: x.rolling(20, min_periods=10).std())
        result['bb_upper'] = result['bb_mid'] + 2 * bb_std
        result['bb_lower'] = result['bb_mid'] - 2 * bb_std
        result['bb_width'] = (result['bb_upper'] - result['bb_lower']) / (result['bb_mid'] + 1e-8)
        result['bb_position'] = (result['Close'] - result['bb_lower']) / (result['bb_upper'] - result['bb_lower'] + 1e-8)
        
        # ATR
        high_low = result['High'] - result['Low']
        high_close = (result['High'] - result['Close'].shift(1)).abs()
        low_close = (result['Low'] - result['Close'].shift(1)).abs()
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        result['atr_14'] = grouped[tr.name].transform(lambda x: x.rolling(14, min_periods=7).mean()) if tr.name in result.columns else tr.rolling(14, min_periods=7).mean()
        result['atr_ratio'] = result['atr_14'] / (result['Close'] + 1e-8)
        
        # æ¢æ‰‹ç‡å› å­
        if 'turnover' in result.columns:
            result['turnover_5d_avg'] = grouped['turnover'].transform(
                lambda x: x.rolling(5, min_periods=3).mean()
            )
            result['turnover_20d_avg'] = grouped['turnover'].transform(
                lambda x: x.rolling(20, min_periods=10).mean()
            )
        
        # ===== é«˜é˜¶å› å­ =====
        # ååº¦
        result['skewness_20d'] = grouped['returns'].transform(
            lambda x: x.rolling(20, min_periods=10).skew()
        )
        
        # å³°åº¦
        result['kurtosis_20d'] = grouped['returns'].transform(
            lambda x: x.rolling(20, min_periods=10).kurt()
        )
        
        # ä¸‹è¡Œæ³¢åŠ¨ç‡
        result['downside_vol_20d'] = grouped['returns'].transform(
            lambda x: x.clip(upper=0).rolling(20, min_periods=10).std() * np.sqrt(252)
        )
        
        # æœ€å¤§å›æ’¤ (æ»šåŠ¨)
        result['max_drawdown_20d'] = grouped['Close'].transform(
            lambda x: (x / x.rolling(20, min_periods=10).max() - 1).rolling(20, min_periods=10).min()
        )
        
        # ===== è‡ªå®šä¹‰å› å­ =====
        for name, factor_info in self._custom_factors.items():
            try:
                result[name] = factor_info['func'](result)
            except Exception:
                pass
        
        # æ¸…ç†ä¸´æ—¶åˆ—
        temp_cols = ['ema_12', 'ema_26', 'bb_mid', 'bb_upper', 'bb_lower']
        result = result.drop(columns=[c for c in temp_cols if c in result.columns], errors='ignore')
        
        return result
    
    def get_factor_names(self) -> List[str]:
        """è·å–æ‰€æœ‰å› å­åç§°"""
        factor_prefixes = [
            'momentum_', 'reversal_', 'volatility_', 'volume_ratio_', 'volume_std_',
            'price_position_', 'ma_bias_', 'macd', 'rsi_', 'bb_', 'atr_',
            'turnover_', 'skewness_', 'kurtosis_', 'downside_vol_', 'max_drawdown_'
        ]
        return factor_prefixes


# ==================== å› å­éªŒè¯å™¨ ====================

class FactorValidator:
    """
    å› å­éªŒè¯å™¨
    
    æ•´åˆV3.3 Tear Sheet + V4.1 Alphaåˆ†æï¼Œå¯¹å› å­è¿›è¡Œå…¨é¢çš„æœ‰æ•ˆæ€§æ£€éªŒã€‚
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
    
    def validate_factor(self, factor_values: pd.Series, forward_returns: pd.Series,
                         benchmark_returns: pd.Series = None,
                         factor_name: str = "unnamed") -> FactorResult:
        """
        éªŒè¯å•ä¸ªå› å­çš„æœ‰æ•ˆæ€§
        
        Args:
            factor_values: å› å­å€¼ (æˆªé¢æ•°æ®)
            forward_returns: æœªæ¥æ”¶ç›Šç‡
            benchmark_returns: åŸºå‡†æ”¶ç›Šç‡ï¼ˆå¯é€‰ï¼‰
            factor_name: å› å­åç§°
        
        Returns:
            FactorResult: å› å­éªŒè¯ç»“æœ
        """
        result = FactorResult(
            name=factor_name,
            category=self._infer_category(factor_name),
            description=f"Factor: {factor_name}"
        )
        
        # å¯¹é½æ•°æ®
        valid_mask = factor_values.notna() & forward_returns.notna()
        fv = factor_values[valid_mask]
        fr = forward_returns[valid_mask]
        
        if len(fv) < 30:
            return result
        
        # 1. ICåˆ†æ (Rank IC)
        ic, p_value = stats.spearmanr(fv, fr)
        result.ic_mean = ic
        result.ic_pvalue = p_value
        result.ic_tstat = ic / (1.0 / np.sqrt(len(fv)) + 1e-8)
        
        # 2. åˆ†å±‚å›æµ‹
        try:
            n_groups = min(5, len(fv) // 10)
            if n_groups >= 2:
                fv_ranked = fv.rank(pct=True)
                top_mask = fv_ranked >= (1 - 1/n_groups)
                bottom_mask = fv_ranked <= (1/n_groups)
                
                result.top_return = float(fr[top_mask].mean() * 252) if top_mask.sum() > 0 else 0
                result.bottom_return = float(fr[bottom_mask].mean() * 252) if bottom_mask.sum() > 0 else 0
                result.long_short_return = result.top_return - result.bottom_return
        except Exception:
            pass
        
        # 3. åŸºå‡†å¯¹æ¯”
        if benchmark_returns is not None:
            try:
                aligned_br = benchmark_returns.reindex(fr.index)
                valid_br = aligned_br.notna()
                if valid_br.sum() > 10:
                    excess = fr[valid_br] - aligned_br[valid_br]
                    result.alpha_vs_benchmark = float(excess.mean() * 252)
                    result.win_rate_vs_benchmark = float((excess > 0).mean())
            except Exception:
                pass
        
        # 4. æœ‰æ•ˆæ€§åˆ¤å®š
        result.effectiveness_score = self._calc_effectiveness_score(result)
        result.is_effective = result.effectiveness_score >= 0.5
        
        return result
    
    def validate_all_factors(self, panel: pd.DataFrame, factor_columns: List[str],
                              return_col: str = 'returns', forward_periods: int = 5,
                              stock_col: str = 'stock_code', date_col: str = 'date',
                              benchmark_returns: pd.Series = None) -> Dict[str, FactorResult]:
        """
        æ‰¹é‡éªŒè¯æ‰€æœ‰å› å­
        
        Args:
            panel: é¢æ¿æ•°æ®
            factor_columns: å› å­åˆ—ååˆ—è¡¨
            return_col: æ”¶ç›Šç‡åˆ—å
            forward_periods: å‰ç»æœŸ
            stock_col: è‚¡ç¥¨ä»£ç åˆ—å
            date_col: æ—¥æœŸåˆ—å
            benchmark_returns: åŸºå‡†æ”¶ç›Šç‡
        
        Returns:
            Dict[str, FactorResult]: å› å­éªŒè¯ç»“æœå­—å…¸
        """
        if self.verbose:
            print(f"\n  ğŸ”¬ å¼€å§‹å› å­éªŒè¯: {len(factor_columns)} ä¸ªå› å­")
        
        results = {}
        
        # è®¡ç®—å‰ç»æ”¶ç›Šç‡
        panel = panel.copy()
        panel['forward_return'] = panel.groupby(stock_col)[return_col].shift(-forward_periods)
        
        for i, col in enumerate(factor_columns):
            if col not in panel.columns:
                continue
            
            # ä½¿ç”¨æœ€æ–°æˆªé¢æ•°æ®è¿›è¡ŒICè®¡ç®—
            dates = panel[date_col].unique()
            ic_list = []
            
            for dt in dates[-60:]:  # ä½¿ç”¨æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥
                cross_section = panel[panel[date_col] == dt]
                fv = cross_section[col]
                fr = cross_section['forward_return']
                
                valid = fv.notna() & fr.notna()
                if valid.sum() >= 5:  # é™ä½é˜ˆå€¼ä»¥æ”¯æŒå°è‚¡ç¥¨æ± 
                    ic, _ = stats.spearmanr(fv[valid], fr[valid])
                    if not np.isnan(ic):
                        ic_list.append(ic)
            
            if len(ic_list) < 3:  # é™ä½é˜ˆå€¼ä»¥æ”¯æŒå°æ ·æœ¬
                continue
            
            ic_series = pd.Series(ic_list)
            
            result = FactorResult(
                name=col,
                category=self._infer_category(col),
                description=f"Factor: {col}",
                ic_mean=float(ic_series.mean()),
                ic_std=float(ic_series.std()),
                ir=float(ic_series.mean() / (ic_series.std() + 1e-8)),
                ic_series=ic_series
            )
            
            # tæ£€éªŒ
            if len(ic_list) > 2:
                t_stat, p_val = stats.ttest_1samp(ic_list, 0)
                result.ic_tstat = float(t_stat)
                result.ic_pvalue = float(p_val)
            
            # åˆ†å±‚å›æµ‹ (ä½¿ç”¨æœ€æ–°æˆªé¢)
            latest_date = dates[-1]
            latest_cs = panel[panel[date_col] == latest_date]
            fv = latest_cs[col]
            fr = latest_cs['forward_return']
            valid = fv.notna() & fr.notna()
            
            if valid.sum() >= 20:
                fv_ranked = fv[valid].rank(pct=True)
                top_mask = fv_ranked >= 0.8
                bottom_mask = fv_ranked <= 0.2
                
                result.top_return = float(fr[valid][top_mask].mean() * 252) if top_mask.sum() > 0 else 0
                result.bottom_return = float(fr[valid][bottom_mask].mean() * 252) if bottom_mask.sum() > 0 else 0
                result.long_short_return = result.top_return - result.bottom_return
            
            # æœ‰æ•ˆæ€§åˆ¤å®š
            result.effectiveness_score = self._calc_effectiveness_score(result)
            result.is_effective = result.effectiveness_score >= 0.5
            
            results[col] = result
        
        effective_count = sum(1 for r in results.values() if r.is_effective)
        if self.verbose:
            print(f"    âœ“ éªŒè¯å®Œæˆ: {len(results)} ä¸ªå› å­, æœ‰æ•ˆ: {effective_count} ä¸ª")
        
        return results
    
    def _calc_effectiveness_score(self, result: FactorResult) -> float:
        """è®¡ç®—å› å­æœ‰æ•ˆæ€§ç»¼åˆå¾—åˆ† (0-1)"""
        score = 0.0
        
        # ICå‡å€¼ (æƒé‡: 30%)
        ic_abs = abs(result.ic_mean)
        if ic_abs > 0.05:
            score += 0.3
        elif ic_abs > 0.03:
            score += 0.2
        elif ic_abs > 0.01:
            score += 0.1
        
        # IR (æƒé‡: 30%)
        ir_abs = abs(result.ir)
        if ir_abs > 0.5:
            score += 0.3
        elif ir_abs > 0.3:
            score += 0.2
        elif ir_abs > 0.1:
            score += 0.1
        
        # å¤šç©ºæ”¶ç›Š (æƒé‡: 20%)
        ls = abs(result.long_short_return)
        if ls > 0.2:
            score += 0.2
        elif ls > 0.1:
            score += 0.15
        elif ls > 0.05:
            score += 0.1
        
        # ç»Ÿè®¡æ˜¾è‘—æ€§ (æƒé‡: 20%)
        if result.ic_pvalue < 0.01:
            score += 0.2
        elif result.ic_pvalue < 0.05:
            score += 0.15
        elif result.ic_pvalue < 0.1:
            score += 0.1
        
        return score
    
    def _infer_category(self, name: str) -> str:
        """æ¨æ–­å› å­ç±»åˆ«"""
        if any(k in name for k in ['momentum', 'reversal', 'ma_bias']):
            return "åŠ¨é‡/åè½¬"
        elif any(k in name for k in ['volatility', 'downside_vol', 'atr', 'bb_width']):
            return "æ³¢åŠ¨ç‡"
        elif any(k in name for k in ['volume', 'turnover']):
            return "æµåŠ¨æ€§"
        elif any(k in name for k in ['rsi', 'macd', 'bb_position', 'price_position']):
            return "æŠ€æœ¯æŒ‡æ ‡"
        elif any(k in name for k in ['pe', 'pb', 'ps', 'roe', 'eps']):
            return "åŸºæœ¬é¢"
        elif any(k in name for k in ['skewness', 'kurtosis', 'max_drawdown']):
            return "é«˜é˜¶ç»Ÿè®¡"
        return "å…¶ä»–"


# ==================== ç»Ÿä¸€å› å­å±‚ ====================

class UnifiedFactorLayer:
    """
    V6.0 ç»Ÿä¸€å› å­å±‚
    
    æ•´åˆå› å­è®¡ç®—ã€éªŒè¯å’Œç­›é€‰çš„å®Œæ•´æµç¨‹ã€‚
    """
    
    def __init__(self, verbose: bool = True, top_n_stocks: int = 20):
        """
        Args:
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            top_n_stocks: å€™é€‰è‚¡ç¥¨æ± å¤§å°
        """
        self.verbose = verbose
        self.top_n_stocks = top_n_stocks
        self.calculator = FactorCalculator()
        self.validator = FactorValidator(verbose=verbose)
    
    def process(self, panel: pd.DataFrame, benchmark_returns: pd.Series = None,
                stock_col: str = 'stock_code', date_col: str = 'date') -> FactorLayerOutput:
        """
        æ‰§è¡Œå®Œæ•´çš„å› å­å±‚å¤„ç†æµç¨‹
        
        Args:
            panel: é¢æ¿æ•°æ® (æ¥è‡ªæ•°æ®å±‚)
            benchmark_returns: åŸºå‡†æ”¶ç›Šç‡ (æ¥è‡ªæ•°æ®å±‚)
            stock_col: è‚¡ç¥¨ä»£ç åˆ—å
            date_col: æ—¥æœŸåˆ—å
        
        Returns:
            FactorLayerOutput: å› å­å±‚å®Œæ•´è¾“å‡º
        """
        output = FactorLayerOutput()
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ”¬ V6.0 ç»Ÿä¸€å› å­å±‚")
            print(f"{'='*60}")
        
        # 1. è®¡ç®—æ‰€æœ‰å› å­
        if self.verbose:
            print(f"\n  ğŸ“ è®¡ç®—å› å­...")
        
        factor_panel = self.calculator.calculate_all(panel, stock_col=stock_col, date_col=date_col)
        
        # è¯†åˆ«å› å­åˆ—
        base_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'returns', 'log_returns',
                     stock_col, date_col, 'stock_name', 'industry', 'turnover',
                     'volatility_20d', 'momentum_20d', 'momentum_60d']
        factor_columns = [c for c in factor_panel.columns 
                         if c not in base_cols and factor_panel[c].dtype in ['float64', 'float32', 'int64']]
        
        if self.verbose:
            print(f"    âœ“ è®¡ç®—å®Œæˆ: {len(factor_columns)} ä¸ªå› å­")
        
        # 2. éªŒè¯å› å­æœ‰æ•ˆæ€§
        all_results = self.validator.validate_all_factors(
            factor_panel, factor_columns,
            return_col='returns', forward_periods=5,
            stock_col=stock_col, date_col=date_col,
            benchmark_returns=benchmark_returns
        )
        output.all_factors = all_results
        
        # 3. ç­›é€‰æœ‰æ•ˆå› å­
        effective = [r for r in all_results.values() if r.is_effective]
        effective.sort(key=lambda x: x.effectiveness_score, reverse=True)
        
        # Fallback: å¦‚æœæ²¡æœ‰é€šè¿‡ä¸¥æ ¼ç­›é€‰çš„å› å­ï¼Œä½¿ç”¨æ‰€æœ‰å› å­æŒ‰å¾—åˆ†æ’åº
        if not effective and all_results:
            all_sorted = sorted(all_results.values(), key=lambda x: x.effectiveness_score, reverse=True)
            # å–å¾—åˆ†æœ€é«˜çš„Top Nä¸ªå› å­ä½œä¸ºå€™é€‰
            effective = all_sorted[:min(15, len(all_sorted))]
            if self.verbose:
                print(f"    âš ï¸ æ— ä¸¥æ ¼æœ‰æ•ˆå› å­ï¼Œä½¿ç”¨Top {len(effective)} å› å­ä½œä¸ºå€™é€‰")
        
        output.effective_factors = effective
        
        if self.verbose:
            print(f"\n  ğŸ“Š æœ‰æ•ˆå› å­æ’å (Top 10):")
            for i, f in enumerate(effective[:10], 1):
                print(f"    {i:2d}. {f.name:<25s} IC={f.ic_mean:+.4f}  IR={f.ir:+.3f}  "
                      f"L/S={f.long_short_return:+.2%}  Score={f.effectiveness_score:.2f}")
        
        # 4. æ„å»ºå› å­çŸ©é˜µ
        effective_names = [f.name for f in effective[:30]]  # å–Top30æœ‰æ•ˆå› å­
        if effective_names:
            valid_factor_cols = [n for n in effective_names if n in factor_panel.columns]
            if valid_factor_cols:
                output.factor_matrix = factor_panel[[stock_col, date_col] + valid_factor_cols].copy()
        
        # Fallback: å¦‚æœå› å­çŸ©é˜µä»ä¸ºç©ºï¼Œä½¿ç”¨æ‰€æœ‰æ•°å€¼å› å­åˆ—
        if output.factor_matrix is None:
            all_factor_cols = [c for c in factor_columns if c in factor_panel.columns][:20]
            if all_factor_cols:
                output.factor_matrix = factor_panel[[stock_col, date_col] + all_factor_cols].copy()
                if self.verbose:
                    print(f"    âš ï¸ ä½¿ç”¨å…¨éƒ¨å› å­æ„å»ºå› å­çŸ©é˜µ: {len(all_factor_cols)} åˆ—")
        
        # 5. å› å­ç›¸å…³æ€§åˆ†æ
        if effective_names and len(effective_names) > 1:
            latest_date = factor_panel[date_col].max()
            latest_cs = factor_panel[factor_panel[date_col] == latest_date]
            valid_cols = [c for c in effective_names if c in latest_cs.columns]
            if valid_cols:
                output.correlation_matrix = latest_cs[valid_cols].corr()
        
        # 6. ç»¼åˆé€‰è‚¡
        output.candidate_stocks = self._select_candidates(
            factor_panel, effective, stock_col, date_col
        )
        
        # 7. ç»Ÿè®¡æ‘˜è¦
        output.stats = {
            "total_factors_calculated": len(factor_columns),
            "total_factors_validated": len(all_results),
            "effective_factors": len(effective),
            "candidate_stocks": len(output.candidate_stocks),
            "top_factor": effective[0].name if effective else "N/A",
            "top_factor_ic": effective[0].ic_mean if effective else 0,
        }
        
        if self.verbose:
            print(f"\n  âœ… å› å­å±‚å¤„ç†å®Œæˆ")
            print(f"     æœ‰æ•ˆå› å­: {output.stats['effective_factors']} ä¸ª")
            print(f"     å€™é€‰è‚¡ç¥¨: {output.stats['candidate_stocks']} åª")
        
        return output
    
    def _select_candidates(self, panel: pd.DataFrame, effective_factors: List[FactorResult],
                            stock_col: str, date_col: str) -> List[Dict[str, Any]]:
        """åŸºäºæœ‰æ•ˆå› å­ç»¼åˆé€‰è‚¡"""
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå› å­ï¼Œä½¿ç”¨åŸºç¡€æŒ‡æ ‡é€‰è‚¡
        if not effective_factors:
            return self._fallback_select(panel, stock_col, date_col)
        
        # ä½¿ç”¨æœ€æ–°æˆªé¢æ•°æ®
        latest_date = panel[date_col].max()
        latest = panel[panel[date_col] == latest_date].copy()
        
        if len(latest) == 0:
            return []
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        score_cols = []
        for factor in effective_factors[:15]:  # ä½¿ç”¨Top15å› å­
            col = factor.name
            if col not in latest.columns:
                continue
            
            # æ ¹æ®ICæ–¹å‘å†³å®šæ’åæ–¹å‘
            rank_col = f'{col}_rank'
            if factor.ic_mean > 0:
                latest[rank_col] = latest[col].rank(pct=True, ascending=True)
            else:
                latest[rank_col] = latest[col].rank(pct=True, ascending=False)
            
            # åŠ æƒ (æŒ‰effectiveness_score)
            latest[rank_col] = latest[rank_col] * factor.effectiveness_score
            score_cols.append(rank_col)
        
        if not score_cols:
            return self._fallback_select(panel, stock_col, date_col)
        
        latest['composite_score'] = latest[score_cols].mean(axis=1)
        latest = latest.sort_values('composite_score', ascending=False)
        
        # é€‰å–Top N
        candidates = []
        for _, row in latest.head(self.top_n_stocks).iterrows():
            candidates.append({
                'code': row[stock_col],
                'name': row.get('stock_name', row[stock_col]),
                'composite_score': float(row['composite_score']),
                'industry': row.get('industry', ''),
                'latest_price': float(row.get('Close', 0)),
                'returns_20d': float(row.get('momentum_20d', 0)) if 'momentum_20d' in row.index else 0,
            })
        
        return candidates
    
    def _fallback_select(self, panel: pd.DataFrame, stock_col: str, date_col: str) -> List[Dict[str, Any]]:
        """å›é€€é€‰è‚¡: å½“æ— æœ‰æ•ˆå› å­æ—¶ï¼ŒåŸºäºåŸºç¡€æŒ‡æ ‡é€‰è‚¡"""
        latest_date = panel[date_col].max()
        latest = panel[panel[date_col] == latest_date].copy()
        
        if len(latest) == 0:
            return []
        
        # ä½¿ç”¨åŠ¨é‡å’Œæ³¢åŠ¨ç‡ç­‰åŸºç¡€æŒ‡æ ‡æ’åº
        score_cols = []
        for col in ['momentum_20d', 'momentum_60d', 'returns']:
            if col in latest.columns:
                rank_col = f'{col}_rank'
                latest[rank_col] = latest[col].rank(pct=True, ascending=True)
                score_cols.append(rank_col)
        
        if not score_cols:
            # æœ€åå›é€€: è¿”å›æ‰€æœ‰è‚¡ç¥¨
            candidates = []
            for _, row in latest.iterrows():
                candidates.append({
                    'code': row[stock_col],
                    'name': row.get('stock_name', row[stock_col]),
                    'composite_score': 0.5,
                    'industry': row.get('industry', ''),
                    'latest_price': float(row.get('Close', 0)),
                    'returns_20d': 0,
                })
            return candidates[:self.top_n_stocks]
        
        latest['composite_score'] = latest[score_cols].mean(axis=1)
        latest = latest.sort_values('composite_score', ascending=False)
        
        candidates = []
        for _, row in latest.head(self.top_n_stocks).iterrows():
            candidates.append({
                'code': row[stock_col],
                'name': row.get('stock_name', row[stock_col]),
                'composite_score': float(row['composite_score']),
                'industry': row.get('industry', ''),
                'latest_price': float(row.get('Close', 0)),
                'returns_20d': float(row.get('momentum_20d', 0)) if 'momentum_20d' in row.index else 0,
            })
        
        if self.verbose:
            print(f"    âš ï¸ ä½¿ç”¨åŸºç¡€æŒ‡æ ‡å›é€€é€‰è‚¡: {len(candidates)} åª")
        
        return candidates


# ==================== ä¾¿æ·å‡½æ•° ====================

def run_factor_analysis(panel: pd.DataFrame, benchmark_returns: pd.Series = None,
                         verbose: bool = True, top_n: int = 20) -> FactorLayerOutput:
    """
    ä¾¿æ·å‡½æ•°ï¼šè¿è¡Œå®Œæ•´çš„å› å­åˆ†æ
    
    Args:
        panel: é¢æ¿æ•°æ®
        benchmark_returns: åŸºå‡†æ”¶ç›Šç‡
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
        top_n: å€™é€‰è‚¡ç¥¨æ•°é‡
    
    Returns:
        FactorLayerOutput: å› å­å±‚è¾“å‡º
    """
    layer = UnifiedFactorLayer(verbose=verbose, top_n_stocks=top_n)
    return layer.process(panel, benchmark_returns)


if __name__ == "__main__":
    print("=" * 60)
    print("V6.0 ç»Ÿä¸€å› å­å±‚æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=252, freq='B')
    stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA']
    
    panels = []
    for stock in stocks:
        price = 100 * np.exp(np.cumsum(np.random.randn(252) * 0.02))
        df = pd.DataFrame({
            'date': dates,
            'stock_code': stock,
            'stock_name': stock,
            'industry': 'Tech',
            'Open': price * (1 + np.random.randn(252) * 0.01),
            'High': price * (1 + abs(np.random.randn(252) * 0.02)),
            'Low': price * (1 - abs(np.random.randn(252) * 0.02)),
            'Close': price,
            'Volume': np.random.randint(1000000, 10000000, 252).astype(float),
        })
        df['returns'] = df['Close'].pct_change()
        df['turnover'] = df['Volume'] / df['Volume'].rolling(20).mean()
        panels.append(df)
    
    panel = pd.concat(panels, ignore_index=True)
    
    # è¿è¡Œå› å­åˆ†æ
    output = run_factor_analysis(panel, verbose=True, top_n=3)
    
    print(f"\nç»Ÿè®¡: {output.stats}")
    print(f"\nå€™é€‰è‚¡ç¥¨:")
    for s in output.candidate_stocks:
        print(f"  {s['code']}: score={s['composite_score']:.4f}")
