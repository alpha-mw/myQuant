#!/usr/bin/env python3
"""
Quant-Investor V6.0 - ç»Ÿä¸€æ•°æ®å±‚ (Unified Data Layer)

æ•´åˆæ‰€æœ‰å†å²ç‰ˆæœ¬çš„æ•°æ®èƒ½åŠ›ï¼š
- V2.7: æŒä¹…åŒ–æ•°æ®å­˜å‚¨ (SQLite + Parquet)
- V3.0: æœŸè´§/æœŸæƒ/è¡Œä¸šæ•°æ®
- V4.0: ç»Ÿä¸€æ•°æ®è·å– (Tushare/yfinance/FRED)
- V4.1: åŸºå‡†æ•°æ® (æŒ‡æ•°æˆåˆ†è‚¡/åŸºå‡†æ”¶ç›Š)
- V5.0: æ•°æ®æ¸…æ´— (å»æå€¼/ç¼ºå¤±å€¼/æ ‡å‡†åŒ–/åå·®å¤„ç†)

è®¾è®¡åŸåˆ™ï¼š
1. æ‰€æœ‰æ•°æ®è‡ªåŠ¨æŒä¹…åŒ–ï¼Œæ”¯æŒå¢é‡æ›´æ–°
2. ç»Ÿä¸€çš„æ•°æ®æ¥å£ï¼Œå±è”½åº•å±‚æ•°æ®æºå·®å¼‚
3. å†…ç½®æ•°æ®æ¸…æ´—æµæ°´çº¿ï¼Œç¡®ä¿æ•°æ®è´¨é‡
4. æ”¯æŒæ—¶ç‚¹æ•°æ®(Point-in-Time)ï¼Œé˜²æ­¢å‰è§†åå·®
"""

import os
import sys
import json
import sqlite3
import hashlib
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field, asdict
from pathlib import Path

# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================

@dataclass
class MarketConfig:
    """å¸‚åœºé…ç½®"""
    name: str
    indices: List[str]
    index_codes: Dict[str, str]
    data_source: str
    currency: str
    benchmark_symbol: str  # åŸºå‡†æŒ‡æ•°ä»£ç 


MARKET_CONFIGS = {
    "CN": MarketConfig(
        name="Aè‚¡å¸‚åœº",
        indices=["æ²ªæ·±300", "ä¸­è¯1000"],
        index_codes={"æ²ªæ·±300": "000300.SH", "ä¸­è¯1000": "000852.SH"},
        data_source="tushare",
        currency="CNY",
        benchmark_symbol="000300.SH"
    ),
    "US": MarketConfig(
        name="ç¾è‚¡å¸‚åœº",
        indices=["çº³æ–¯è¾¾å…‹100", "æ ‡æ™®500"],
        index_codes={"çº³æ–¯è¾¾å…‹100": "^NDX", "æ ‡æ™®500": "^GSPC"},
        data_source="yfinance",
        currency="USD",
        benchmark_symbol="^GSPC"
    )
}


@dataclass
class StockRecord:
    """å•åªè‚¡ç¥¨çš„å®Œæ•´æ•°æ®è®°å½•"""
    code: str
    name: str
    market: str
    industry: str = ""
    sector: str = ""
    price_data: pd.DataFrame = None
    financial_data: Dict = field(default_factory=dict)
    metadata: Dict = field(default_factory=dict)


@dataclass
class UnifiedDataBundle:
    """ç»Ÿä¸€æ•°æ®åŒ… - åŒ…å«åˆ†ææ‰€éœ€çš„å…¨éƒ¨æ•°æ®"""
    market: str
    config: MarketConfig
    fetch_date: str
    
    # æ ¸å¿ƒæ•°æ®
    stock_universe: Dict[str, StockRecord] = field(default_factory=dict)
    benchmark_data: pd.DataFrame = None
    
    # å®è§‚æ•°æ®
    macro_data: Dict[str, pd.Series] = field(default_factory=dict)
    
    # è¡Œä¸šæ•°æ®
    industry_data: Dict[str, Any] = field(default_factory=dict)
    
    # æ¸…æ´—åçš„é¢æ¿æ•°æ® (ç”¨äºå› å­è®¡ç®—)
    panel_data: pd.DataFrame = None
    
    # ç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨ (è‡ªå®šä¹‰è‚¡ç¥¨æ± æ—¶éç©ºï¼Œè¡¨ç¤ºå†³ç­–å±‚åªåˆ†æè¿™äº›è‚¡ç¥¨)
    focus_stocks: Optional[List[str]] = None
    
    # å…ƒä¿¡æ¯
    stats: Dict[str, Any] = field(default_factory=dict)


# ==================== æŒä¹…åŒ–æ•°æ®ç®¡ç†å™¨ ====================

class PersistentDataManager:
    """
    æŒä¹…åŒ–æ•°æ®ç®¡ç†å™¨ (æºè‡ªV2.7)
    
    ä½¿ç”¨SQLiteå­˜å‚¨å…ƒæ•°æ®ï¼ŒParquetå­˜å‚¨æ—¶åºæ•°æ®ã€‚
    æ”¯æŒå¢é‡æ›´æ–°ï¼Œé¿å…é‡å¤ä¸‹è½½ã€‚
    """
    
    def __init__(self, data_dir: str = None):
        self.data_dir = Path(data_dir or os.path.expanduser("~/.quant_investor/data"))
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.db_path = self.data_dir / "metadata.db"
        self._init_db()
    
    def _init_db(self):
        """åˆå§‹åŒ–SQLiteæ•°æ®åº“"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS data_cache (
                cache_key TEXT PRIMARY KEY,
                data_type TEXT,
                market TEXT,
                last_updated TEXT,
                file_path TEXT,
                row_count INTEGER,
                metadata TEXT
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS download_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                market TEXT,
                data_type TEXT,
                status TEXT,
                message TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    def _get_cache_key(self, market: str, data_type: str, symbol: str = "", 
                        start_date: str = "", end_date: str = "") -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        raw = f"{market}_{data_type}_{symbol}_{start_date}_{end_date}"
        return hashlib.md5(raw.encode()).hexdigest()
    
    def is_cached(self, market: str, data_type: str, symbol: str = "",
                   max_age_hours: int = 24) -> bool:
        """æ£€æŸ¥æ•°æ®æ˜¯å¦å·²ç¼“å­˜ä¸”æœªè¿‡æœŸ"""
        cache_key = self._get_cache_key(market, data_type, symbol)
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        cursor.execute("SELECT last_updated, file_path FROM data_cache WHERE cache_key = ?", (cache_key,))
        row = cursor.fetchone()
        conn.close()
        
        if row is None:
            return False
        
        last_updated = datetime.fromisoformat(row[0])
        file_path = row[1]
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        age = datetime.now() - last_updated
        return age.total_seconds() < max_age_hours * 3600
    
    def save_dataframe(self, df: pd.DataFrame, market: str, data_type: str, 
                        symbol: str = "", metadata: Dict = None) -> str:
        """ä¿å­˜DataFrameåˆ°Parquetæ–‡ä»¶"""
        cache_key = self._get_cache_key(market, data_type, symbol)
        
        # ç”Ÿæˆæ–‡ä»¶è·¯å¾„
        subdir = self.data_dir / market.lower() / data_type
        subdir.mkdir(parents=True, exist_ok=True)
        
        safe_symbol = symbol.replace(".", "_").replace("^", "_").replace("/", "_")
        file_path = str(subdir / f"{safe_symbol or 'data'}_{cache_key[:8]}.parquet")
        
        # ä¿å­˜Parquet
        df.to_parquet(file_path, index=True)
        
        # æ›´æ–°å…ƒæ•°æ®
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        cursor.execute("""
            INSERT OR REPLACE INTO data_cache 
            (cache_key, data_type, market, last_updated, file_path, row_count, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            cache_key, data_type, market, datetime.now().isoformat(),
            file_path, len(df), json.dumps(metadata or {})
        ))
        conn.commit()
        conn.close()
        
        return file_path
    
    def load_dataframe(self, market: str, data_type: str, symbol: str = "") -> Optional[pd.DataFrame]:
        """ä»ç¼“å­˜åŠ è½½DataFrame"""
        cache_key = self._get_cache_key(market, data_type, symbol)
        
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        cursor.execute("SELECT file_path FROM data_cache WHERE cache_key = ?", (cache_key,))
        row = cursor.fetchone()
        conn.close()
        
        if row and os.path.exists(row[0]):
            return pd.read_parquet(row[0])
        return None
    
    def log_download(self, market: str, data_type: str, status: str, message: str = ""):
        """è®°å½•ä¸‹è½½æ—¥å¿—"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO download_log (timestamp, market, data_type, status, message)
            VALUES (?, ?, ?, ?, ?)
        """, (datetime.now().isoformat(), market, data_type, status, message))
        conn.commit()
        conn.close()


# ==================== æ•°æ®æ¸…æ´—å™¨ ====================

class DataCleaner:
    """
    æ•°æ®æ¸…æ´—å™¨ (æºè‡ªV5.0)
    
    æä¾›å®Œæ•´çš„æ•°æ®æ¸…æ´—æµæ°´çº¿ï¼š
    1. å»æå€¼ (Winsorization)
    2. ç¼ºå¤±å€¼å¡«å……
    3. æ ‡å‡†åŒ–
    4. å‰è§†åå·®é˜²æ§
    """
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
    
    def _log(self, msg: str):
        if self.verbose:
            print(f"  [DataCleaner] {msg}")
    
    def winsorize(self, data: pd.DataFrame, columns: List[str] = None,
                   method: str = 'mad', sigma: float = 3.0) -> pd.DataFrame:
        """å»æå€¼å¤„ç†"""
        result = data.copy()
        if columns is None:
            columns = result.select_dtypes(include=[np.number]).columns.tolist()
        
        for col in columns:
            if col not in result.columns:
                continue
            series = result[col].dropna()
            if len(series) == 0:
                continue
            
            if method == 'mad':
                median = series.median()
                mad = np.median(np.abs(series - median))
                lower = median - sigma * 1.4826 * mad
                upper = median + sigma * 1.4826 * mad
            elif method == 'percentile':
                lower = series.quantile(0.01)
                upper = series.quantile(0.99)
            elif method == 'sigma':
                mean = series.mean()
                std = series.std()
                lower = mean - sigma * std
                upper = mean + sigma * std
            else:
                continue
            
            result[col] = result[col].clip(lower=lower, upper=upper)
        
        self._log(f"å»æå€¼å®Œæˆ: {len(columns)} åˆ—, æ–¹æ³•={method}")
        return result
    
    def fill_missing(self, data: pd.DataFrame, columns: List[str] = None,
                      method: str = 'ffill') -> pd.DataFrame:
        """ç¼ºå¤±å€¼å¡«å……"""
        result = data.copy()
        if columns is None:
            columns = result.select_dtypes(include=[np.number]).columns.tolist()
        
        total_filled = 0
        for col in columns:
            if col not in result.columns:
                continue
            missing = result[col].isna().sum()
            if missing == 0:
                continue
            
            if method == 'ffill':
                result[col] = result[col].ffill().bfill()
            elif method == 'median':
                result[col] = result[col].fillna(result[col].median())
            elif method == 'mean':
                result[col] = result[col].fillna(result[col].mean())
            elif method == 'interpolate':
                result[col] = result[col].interpolate(method='linear')
            
            total_filled += missing
        
        self._log(f"ç¼ºå¤±å€¼å¡«å……å®Œæˆ: å…±å¡«å…… {total_filled} ä¸ªç¼ºå¤±å€¼")
        return result
    
    def standardize(self, data: pd.DataFrame, columns: List[str] = None,
                     method: str = 'zscore', by_date: bool = False,
                     date_col: str = 'date') -> pd.DataFrame:
        """æ ‡å‡†åŒ–"""
        result = data.copy()
        if columns is None:
            columns = result.select_dtypes(include=[np.number]).columns.tolist()
        
        def _std(s, m):
            if m == 'zscore':
                return (s - s.mean()) / (s.std() + 1e-8)
            elif m == 'minmax':
                return (s - s.min()) / (s.max() - s.min() + 1e-8)
            elif m == 'rank':
                return s.rank(pct=True)
            return s
        
        for col in columns:
            if col not in result.columns or col == date_col:
                continue
            if by_date and date_col in result.columns:
                result[col] = result.groupby(date_col)[col].transform(lambda x: _std(x, method))
            else:
                result[col] = _std(result[col], method)
        
        self._log(f"æ ‡å‡†åŒ–å®Œæˆ: {len(columns)} åˆ—, æ–¹æ³•={method}")
        return result
    
    def shift_features(self, data: pd.DataFrame, feature_cols: List[str],
                        shift_periods: int = 1, stock_col: str = 'stock_code') -> pd.DataFrame:
        """ç‰¹å¾æ»åå¤„ç†ï¼Œé˜²æ­¢å‰è§†åå·®"""
        result = data.copy()
        if stock_col in result.columns:
            for col in feature_cols:
                if col in result.columns:
                    result[col] = result.groupby(stock_col)[col].shift(shift_periods)
        else:
            for col in feature_cols:
                if col in result.columns:
                    result[col] = result[col].shift(shift_periods)
        
        self._log(f"ç‰¹å¾æ»åå¤„ç†å®Œæˆ: {len(feature_cols)} åˆ—, æ»å {shift_periods} æœŸ")
        return result
    
    def clean_pipeline(self, data: pd.DataFrame, columns: List[str] = None,
                        winsorize_method: str = 'mad',
                        fill_method: str = 'ffill',
                        standardize_method: str = 'zscore',
                        by_date: bool = True, date_col: str = 'date') -> pd.DataFrame:
        """å®Œæ•´æ¸…æ´—æµæ°´çº¿: å»æå€¼ -> ç¼ºå¤±å€¼å¡«å…… -> æ ‡å‡†åŒ–"""
        self._log("å¼€å§‹æ•°æ®æ¸…æ´—æµæ°´çº¿...")
        result = self.winsorize(data, columns, method=winsorize_method)
        result = self.fill_missing(result, columns, method=fill_method)
        result = self.standardize(result, columns, method=standardize_method, 
                                   by_date=by_date, date_col=date_col)
        self._log("æ•°æ®æ¸…æ´—æµæ°´çº¿å®Œæˆ")
        return result


# ==================== ç»Ÿä¸€æ•°æ®å±‚ ====================

class UnifiedDataLayer:
    """
    V6.0 ç»Ÿä¸€æ•°æ®å±‚
    
    æ•´åˆæ‰€æœ‰æ•°æ®è·å–ã€æŒä¹…åŒ–å’Œæ¸…æ´—èƒ½åŠ›ï¼Œæä¾›ç»Ÿä¸€çš„æ•°æ®æ¥å£ã€‚
    """
    
    def __init__(self, market: str = "US", lookback_years: int = 3, 
                  verbose: bool = True, cache_hours: int = 24):
        """
        åˆå§‹åŒ–ç»Ÿä¸€æ•°æ®å±‚
        
        Args:
            market: å¸‚åœºç±»å‹ ("CN" æˆ– "US")
            lookback_years: å†å²æ•°æ®å›æº¯å¹´æ•°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
            cache_hours: ç¼“å­˜æœ‰æ•ˆæœŸï¼ˆå°æ—¶ï¼‰
        """
        self.market = market.upper()
        if self.market not in MARKET_CONFIGS:
            raise ValueError(f"ä¸æ”¯æŒçš„å¸‚åœº: {market}. æ”¯æŒ: {list(MARKET_CONFIGS.keys())}")
        
        self.config = MARKET_CONFIGS[self.market]
        self.lookback_years = lookback_years
        self.verbose = verbose
        self.cache_hours = cache_hours
        
        self.end_date = datetime.now()
        self.start_date = self.end_date - timedelta(days=lookback_years * 365)
        
        # åˆå§‹åŒ–å­æ¨¡å—
        self.storage = PersistentDataManager()
        self.cleaner = DataCleaner(verbose=verbose)
        
        # åˆå§‹åŒ–æ•°æ®æºå®¢æˆ·ç«¯
        self._clients = {}
        self._init_clients()
        
        if self.verbose:
            print(f"\n{'='*60}")
            print(f"ğŸ“Š V6.0 ç»Ÿä¸€æ•°æ®å±‚åˆå§‹åŒ–")
            print(f"   å¸‚åœº: {self.config.name}")
            print(f"   æ•°æ®èŒƒå›´: {self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}")
            print(f"   ç¼“å­˜ç›®å½•: {self.storage.data_dir}")
            print(f"{'='*60}")
    
    def _init_clients(self):
        """åˆå§‹åŒ–æ•°æ®æºå®¢æˆ·ç«¯"""
        # Tushare (Aè‚¡)
        if self.market == "CN":
            try:
                import tushare as ts
                token = os.getenv("TUSHARE_TOKEN", "")
                if token:
                    ts.set_token(token)
                self._clients['tushare'] = ts.pro_api()
                if self.verbose:
                    print(f"  âœ… Tushare åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                if self.verbose:
                    print(f"  âš ï¸ Tushare åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # yfinance (ç¾è‚¡/å…¨çƒ)
        try:
            import yfinance as yf
            self._clients['yfinance'] = yf
            if self.verbose:
                print(f"  âœ… yfinance åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            if self.verbose:
                print(f"  âš ï¸ yfinance åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # FRED (å®è§‚æ•°æ®)
        try:
            from fredapi import Fred
            fred_key = os.getenv("FRED_API_KEY", "")
            if fred_key:
                self._clients['fred'] = Fred(api_key=fred_key)
                if self.verbose:
                    print(f"  âœ… FRED åˆå§‹åŒ–æˆåŠŸ")
        except Exception:
            pass
    
    # ==================== æ ¸å¿ƒæ•°æ®è·å– ====================
    
    def fetch_all(self, stock_pool: List[str] = None) -> UnifiedDataBundle:
        """
        è·å–å…¨éƒ¨æ•°æ®ï¼Œè¿”å›ç»Ÿä¸€æ•°æ®åŒ…
        
        Args:
            stock_pool: æŒ‡å®šè‚¡ç¥¨æ± ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æŒ‡æ•°æˆåˆ†è‚¡ï¼‰
        
        Returns:
            UnifiedDataBundle: åŒ…å«æ‰€æœ‰æ•°æ®çš„ç»Ÿä¸€æ•°æ®åŒ…
        """
        bundle = UnifiedDataBundle(
            market=self.market,
            config=self.config,
            fetch_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        
        if self.verbose:
            print(f"\n{'â”€'*50}")
            print(f"ğŸ“¥ å¼€å§‹è·å– {self.config.name} æ•°æ®...")
            print(f"{'â”€'*50}")
        
        # 1. è·å–è‚¡ç¥¨æ±  (è‡ªå®šä¹‰æ—¶è‡ªåŠ¨æ‰©å……æŒ‡æ•°æˆåˆ†è‚¡)
        focus_stocks = None
        if stock_pool:
            bundle.stock_universe, focus_stocks = self._build_expanded_universe(stock_pool)
        else:
            bundle.stock_universe = self._fetch_index_constituents()
        
        bundle.focus_stocks = focus_stocks  # Noneè¡¨ç¤ºå…¨éƒ¨å…³æ³¨
        
        # 2. è·å–ä»·æ ¼æ•°æ®
        bundle.stock_universe = self._fetch_price_data(bundle.stock_universe)
        
        # 3. è·å–åŸºå‡†æ•°æ®
        bundle.benchmark_data = self._fetch_benchmark_data()
        
        # 4. è·å–è´¢åŠ¡æ•°æ®
        bundle.stock_universe = self._fetch_financial_data(bundle.stock_universe)
        
        # 5. è·å–å®è§‚æ•°æ®
        bundle.macro_data = self._fetch_macro_data()
        
        # 6. æ„å»ºé¢æ¿æ•°æ®
        bundle.panel_data = self._build_panel_data(bundle.stock_universe)
        
        # 7. ç»Ÿè®¡ä¿¡æ¯
        valid_stocks = sum(1 for s in bundle.stock_universe.values() 
                          if s.price_data is not None and len(s.price_data) > 0)
        bundle.stats = {
            "total_stocks": len(bundle.stock_universe),
            "valid_stocks": valid_stocks,
            "focus_stocks": len(focus_stocks) if focus_stocks else valid_stocks,
            "benchmark_available": bundle.benchmark_data is not None,
            "macro_indicators": len(bundle.macro_data),
            "panel_rows": len(bundle.panel_data) if bundle.panel_data is not None else 0,
            "date_range": f"{self.start_date.strftime('%Y-%m-%d')} ~ {self.end_date.strftime('%Y-%m-%d')}"
        }
        
        if self.verbose:
            print(f"\n{'â”€'*50}")
            print(f"âœ… æ•°æ®è·å–å®Œæˆ!")
            print(f"   è‚¡ç¥¨æ€»æ•°: {bundle.stats['total_stocks']}")
            print(f"   æœ‰æ•ˆæ•°æ®: {bundle.stats['valid_stocks']} åª")
            print(f"   åŸºå‡†æ•°æ®: {'âœ“' if bundle.stats['benchmark_available'] else 'âœ—'}")
            print(f"   å®è§‚æŒ‡æ ‡: {bundle.stats['macro_indicators']} ä¸ª")
            print(f"   é¢æ¿è¡Œæ•°: {bundle.stats['panel_rows']}")
            print(f"{'â”€'*50}")
        
        return bundle
    
    # ==================== è‚¡ç¥¨æ± è·å– ====================
    
    def _build_custom_universe(self, stock_pool: List[str]) -> Dict[str, StockRecord]:
        """æ„å»ºè‡ªå®šä¹‰è‚¡ç¥¨æ± """
        universe = {}
        for code in stock_pool:
            universe[code] = StockRecord(code=code, name=code, market=self.market)
        return universe
    
    def _build_expanded_universe(self, stock_pool: List[str]) -> Tuple[Dict[str, StockRecord], List[str]]:
        """
        æ„å»ºæ‰©å……åçš„è‚¡ç¥¨æ± ï¼š
        - è‡ªå®šä¹‰è‚¡ç¥¨æ± çš„è‚¡ç¥¨æ ‡è®°ä¸ºfocus_stocks
        - è‡ªåŠ¨è¡¥å……æŒ‡æ•°æˆåˆ†è‚¡ä½œä¸ºå› å­éªŒè¯çš„å®Œæ•´æˆªé¢æ ·æœ¬
        
        Returns:
            (expanded_universe, focus_stocks): æ‰©å……åçš„universeå’Œç”¨æˆ·å…³æ³¨çš„è‚¡ç¥¨åˆ—è¡¨
        """
        # 1. å…ˆè·å–æŒ‡æ•°æˆåˆ†è‚¡ä½œä¸ºå®Œæ•´æ ·æœ¬
        full_universe = self._fetch_index_constituents()
        
        # 2. ç¡®ä¿ç”¨æˆ·æŒ‡å®šçš„è‚¡ç¥¨éƒ½åœ¨å…¶ä¸­
        focus_stocks = list(stock_pool)
        for code in focus_stocks:
            if code not in full_universe:
                full_universe[code] = StockRecord(code=code, name=code, market=self.market)
        
        if self.verbose:
            print(f"  ğŸ“Š æ ·æœ¬æ‰©å……: ç”¨æˆ·å…³æ³¨ {len(focus_stocks)} åª â†’ å®Œæ•´æ ·æœ¬ {len(full_universe)} åª")
        
        return full_universe, focus_stocks
    
    def _fetch_index_constituents(self) -> Dict[str, StockRecord]:
        """è·å–æŒ‡æ•°æˆåˆ†è‚¡"""
        if self.market == "CN":
            return self._fetch_cn_constituents()
        else:
            return self._fetch_us_constituents()
    
    def _fetch_cn_constituents(self) -> Dict[str, StockRecord]:
        """è·å–Aè‚¡æŒ‡æ•°æˆåˆ†è‚¡"""
        universe = {}
        ts_pro = self._clients.get('tushare')
        
        if ts_pro is None:
            if self.verbose:
                print("  âš ï¸ Tushareä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤Aè‚¡æ ¸å¿ƒè‚¡ç¥¨æ± ")
            return self._get_default_cn_stocks()
        
        for index_name, index_code in self.config.index_codes.items():
            try:
                if self.verbose:
                    print(f"  è·å– {index_name} æˆåˆ†è‚¡...")
                
                df = ts_pro.index_weight(index_code=index_code)
                if df is not None and len(df) > 0:
                    latest_date = df['trade_date'].max()
                    df = df[df['trade_date'] == latest_date]
                    
                    for _, row in df.iterrows():
                        code = row['con_code']
                        if code not in universe:
                            universe[code] = StockRecord(code=code, name="", market="CN")
                    
                    if self.verbose:
                        print(f"    âœ“ {index_name}: {len(df)} åª")
            except Exception as e:
                if self.verbose:
                    print(f"    âœ— {index_name} è·å–å¤±è´¥: {e}")
        
        # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        try:
            stock_basic = ts_pro.stock_basic(exchange='', list_status='L')
            if stock_basic is not None:
                for code in universe:
                    info = stock_basic[stock_basic['ts_code'] == code]
                    if len(info) > 0:
                        universe[code].name = info.iloc[0]['name']
                        universe[code].industry = info.iloc[0].get('industry', '')
        except Exception:
            pass
        
        return universe if universe else self._get_default_cn_stocks()
    
    def _fetch_us_constituents(self) -> Dict[str, StockRecord]:
        """è·å–ç¾è‚¡æŒ‡æ•°æˆåˆ†è‚¡"""
        # çº³æ–¯è¾¾å…‹100 + æ ‡æ™®500æ ¸å¿ƒè‚¡ç¥¨
        nasdaq100 = [
            "AAPL", "MSFT", "AMZN", "NVDA", "GOOGL", "META", "TSLA", "AVGO", "COST", "NFLX",
            "AMD", "ADBE", "PEP", "CSCO", "TMUS", "INTC", "CMCSA", "TXN", "QCOM", "AMGN",
            "INTU", "AMAT", "ISRG", "HON", "BKNG", "VRTX", "SBUX", "GILD", "MDLZ", "ADI",
            "ADP", "REGN", "LRCX", "PANW", "KLAC", "SNPS", "CDNS", "MELI", "ASML", "PYPL",
            "CRWD", "ABNB", "MRVL", "ORLY", "FTNT", "DASH", "MNST", "CTAS", "DXCM", "ODFL"
        ]
        
        sp500_supplement = [
            "JPM", "V", "JNJ", "UNH", "PG", "MA", "HD", "XOM", "CVX", "BAC",
            "MRK", "ABBV", "KO", "PFE", "LLY", "WMT", "DIS", "MCD", "VZ", "NKE",
            "CRM", "TMO", "ABT", "DHR", "ORCL", "ACN", "WFC", "PM", "RTX", "NEE",
            "BMY", "SCHW", "LOW", "UPS", "GS", "MS", "BLK", "SPGI", "AXP", "CAT"
        ]
        
        all_stocks = list(set(nasdaq100 + sp500_supplement))
        
        universe = {}
        for symbol in all_stocks:
            universe[symbol] = StockRecord(code=symbol, name=symbol, market="US")
        
        if self.verbose:
            print(f"  âœ“ ç¾è‚¡è‚¡ç¥¨æ± : {len(universe)} åª (NASDAQ100 + S&P500æ ¸å¿ƒ)")
        
        return universe
    
    def _get_default_cn_stocks(self) -> Dict[str, StockRecord]:
        """é»˜è®¤Aè‚¡æ ¸å¿ƒè‚¡ç¥¨æ± """
        stocks = {
            "600519.SH": ("è´µå·èŒ…å°", "ç™½é…’"), "000858.SZ": ("äº”ç²®æ¶²", "ç™½é…’"),
            "601318.SH": ("ä¸­å›½å¹³å®‰", "ä¿é™©"), "600036.SH": ("æ‹›å•†é“¶è¡Œ", "é“¶è¡Œ"),
            "000333.SZ": ("ç¾çš„é›†å›¢", "å®¶ç”µ"), "600276.SH": ("æ’ç‘åŒ»è¯", "åŒ»è¯"),
            "601012.SH": ("éš†åŸºç»¿èƒ½", "å…‰ä¼"), "002475.SZ": ("ç«‹è®¯ç²¾å¯†", "ç”µå­"),
            "300750.SZ": ("å®å¾·æ—¶ä»£", "ç”µæ± "), "600900.SH": ("é•¿æ±Ÿç”µåŠ›", "ç”µåŠ›"),
        }
        universe = {}
        for code, (name, industry) in stocks.items():
            universe[code] = StockRecord(code=code, name=name, market="CN", industry=industry)
        return universe
    
    # ==================== ä»·æ ¼æ•°æ®è·å– ====================
    
    def _fetch_price_data(self, universe: Dict[str, StockRecord]) -> Dict[str, StockRecord]:
        """è·å–ä»·æ ¼æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if self.verbose:
            print(f"\n  ğŸ“ˆ è·å–ä»·æ ¼æ•°æ®...")
        
        if self.market == "CN":
            return self._fetch_cn_prices(universe)
        else:
            return self._fetch_us_prices(universe)
    
    def _fetch_cn_prices(self, universe: Dict[str, StockRecord]) -> Dict[str, StockRecord]:
        """è·å–Aè‚¡ä»·æ ¼æ•°æ®"""
        ts_pro = self._clients.get('tushare')
        if ts_pro is None:
            return universe
        
        start_str = self.start_date.strftime('%Y%m%d')
        end_str = self.end_date.strftime('%Y%m%d')
        success = 0
        
        for code, stock in universe.items():
            # æ£€æŸ¥ç¼“å­˜
            if self.storage.is_cached(self.market, "price", code, self.cache_hours):
                cached = self.storage.load_dataframe(self.market, "price", code)
                if cached is not None:
                    stock.price_data = cached
                    success += 1
                    continue
            
            try:
                df = ts_pro.daily(ts_code=code, start_date=start_str, end_date=end_str)
                if df is not None and len(df) > 0:
                    df = df.sort_values('trade_date')
                    df['date'] = pd.to_datetime(df['trade_date'])
                    df = df.set_index('date')
                    df = df.rename(columns={
                        'open': 'Open', 'high': 'High', 'low': 'Low',
                        'close': 'Close', 'vol': 'Volume'
                    })
                    stock.price_data = df[['Open', 'High', 'Low', 'Close', 'Volume']]
                    
                    # æŒä¹…åŒ–
                    self.storage.save_dataframe(stock.price_data, self.market, "price", code)
                    success += 1
            except Exception:
                pass
        
        if self.verbose:
            print(f"    âœ“ Aè‚¡ä»·æ ¼æ•°æ®: {success}/{len(universe)}")
        return universe
    
    def _fetch_us_prices(self, universe: Dict[str, StockRecord]) -> Dict[str, StockRecord]:
        """è·å–ç¾è‚¡ä»·æ ¼æ•°æ®"""
        yf = self._clients.get('yfinance')
        if yf is None:
            return universe
        
        symbols = list(universe.keys())
        
        # æ£€æŸ¥å“ªäº›éœ€è¦ä¸‹è½½
        to_download = []
        for symbol in symbols:
            if self.storage.is_cached(self.market, "price", symbol, self.cache_hours):
                cached = self.storage.load_dataframe(self.market, "price", symbol)
                if cached is not None:
                    universe[symbol].price_data = cached
                    continue
            to_download.append(symbol)
        
        cached_count = len(symbols) - len(to_download)
        if cached_count > 0 and self.verbose:
            print(f"    âœ“ ä»ç¼“å­˜åŠ è½½: {cached_count} åª")
        
        if to_download:
            try:
                if self.verbose:
                    print(f"    â³ ä¸‹è½½ä¸­: {len(to_download)} åª...")
                
                data = yf.download(
                    to_download,
                    start=self.start_date,
                    end=self.end_date,
                    progress=False,
                    auto_adjust=True
                )
                
                success = 0
                for symbol in to_download:
                    try:
                        if len(to_download) > 1 and isinstance(data.columns, pd.MultiIndex):
                            stock_df = data.xs(symbol, level=1, axis=1)
                        elif len(to_download) == 1:
                            stock_df = data
                        else:
                            stock_df = data[symbol] if symbol in data.columns else None
                        
                        if stock_df is not None and len(stock_df.dropna()) > 20:
                            stock_df = stock_df.dropna()
                            universe[symbol].price_data = stock_df[['Open', 'High', 'Low', 'Close', 'Volume']]
                            
                            # æŒä¹…åŒ–
                            self.storage.save_dataframe(
                                universe[symbol].price_data, self.market, "price", symbol
                            )
                            success += 1
                    except Exception:
                        pass
                
                if self.verbose:
                    print(f"    âœ“ æ–°ä¸‹è½½: {success}/{len(to_download)}")
            except Exception as e:
                if self.verbose:
                    print(f"    âœ— æ‰¹é‡ä¸‹è½½å¤±è´¥: {e}")
        
        total_valid = sum(1 for s in universe.values() if s.price_data is not None)
        if self.verbose:
            print(f"    âœ“ æ€»è®¡æœ‰æ•ˆä»·æ ¼æ•°æ®: {total_valid}/{len(universe)}")
        
        return universe
    
    # ==================== åŸºå‡†æ•°æ®è·å– ====================
    
    def _fetch_benchmark_data(self) -> Optional[pd.DataFrame]:
        """è·å–åŸºå‡†æŒ‡æ•°æ•°æ®"""
        if self.verbose:
            print(f"\n  ğŸ“Š è·å–åŸºå‡†æ•°æ®: {self.config.benchmark_symbol}")
        
        # æ£€æŸ¥ç¼“å­˜
        if self.storage.is_cached(self.market, "benchmark", self.config.benchmark_symbol, self.cache_hours):
            cached = self.storage.load_dataframe(self.market, "benchmark", self.config.benchmark_symbol)
            if cached is not None:
                if self.verbose:
                    print(f"    âœ“ ä»ç¼“å­˜åŠ è½½åŸºå‡†æ•°æ®: {len(cached)} æ¡")
                return cached
        
        yf = self._clients.get('yfinance')
        if yf is None:
            return None
        
        try:
            benchmark = yf.download(
                self.config.benchmark_symbol,
                start=self.start_date,
                end=self.end_date,
                progress=False,
                auto_adjust=True
            )
            
            if benchmark is not None and len(benchmark) > 0:
                # å¤„ç†MultiIndexåˆ—
                if isinstance(benchmark.columns, pd.MultiIndex):
                    benchmark.columns = benchmark.columns.get_level_values(0)
                
                self.storage.save_dataframe(
                    benchmark, self.market, "benchmark", self.config.benchmark_symbol
                )
                if self.verbose:
                    print(f"    âœ“ åŸºå‡†æ•°æ®: {len(benchmark)} æ¡")
                return benchmark
        except Exception as e:
            if self.verbose:
                print(f"    âœ— åŸºå‡†æ•°æ®è·å–å¤±è´¥: {e}")
        
        return None
    
    # ==================== è´¢åŠ¡æ•°æ®è·å– ====================
    
    def _fetch_financial_data(self, universe: Dict[str, StockRecord]) -> Dict[str, StockRecord]:
        """è·å–è´¢åŠ¡æ•°æ®"""
        if self.verbose:
            print(f"\n  ğŸ’° è®¡ç®—è´¢åŠ¡æŒ‡æ ‡...")
        
        for code, stock in universe.items():
            if stock.price_data is None or len(stock.price_data) < 20:
                continue
            
            prices = stock.price_data['Close']
            returns = prices.pct_change().dropna()
            
            if len(returns) < 10:
                continue
            
            stock.financial_data = {
                'annual_return': float(returns.mean() * 252),
                'annual_volatility': float(returns.std() * np.sqrt(252)),
                'sharpe_ratio': float((returns.mean() * 252) / (returns.std() * np.sqrt(252) + 1e-8)),
                'max_drawdown': float(self._calc_max_drawdown(prices)),
                'avg_volume': float(stock.price_data['Volume'].mean()),
                'latest_price': float(prices.iloc[-1]),
                'price_52w_high': float(prices.tail(252).max()) if len(prices) >= 252 else float(prices.max()),
                'price_52w_low': float(prices.tail(252).min()) if len(prices) >= 252 else float(prices.min()),
                'return_1m': float(prices.pct_change(21).iloc[-1]) if len(prices) > 21 else 0,
                'return_3m': float(prices.pct_change(63).iloc[-1]) if len(prices) > 63 else 0,
                'return_6m': float(prices.pct_change(126).iloc[-1]) if len(prices) > 126 else 0,
                'return_1y': float(prices.pct_change(252).iloc[-1]) if len(prices) > 252 else 0,
            }
        
        valid = sum(1 for s in universe.values() if s.financial_data)
        if self.verbose:
            print(f"    âœ“ è´¢åŠ¡æŒ‡æ ‡è®¡ç®—å®Œæˆ: {valid} åª")
        
        return universe
    
    def _calc_max_drawdown(self, prices: pd.Series) -> float:
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        peak = prices.expanding(min_periods=1).max()
        drawdown = (prices - peak) / peak
        return drawdown.min()
    
    # ==================== å®è§‚æ•°æ®è·å– ====================
    
    def _fetch_macro_data(self) -> Dict[str, pd.Series]:
        """è·å–å®è§‚ç»æµæ•°æ®"""
        if self.verbose:
            print(f"\n  ğŸŒ è·å–å®è§‚æ•°æ®...")
        
        macro = {}
        yf = self._clients.get('yfinance')
        
        if yf:
            # é€šè¿‡yfinanceè·å–å…³é”®å¸‚åœºæŒ‡æ ‡
            macro_symbols = {
                'VIX': '^VIX',        # ææ…ŒæŒ‡æ•°
                'DXY': 'DX-Y.NYB',    # ç¾å…ƒæŒ‡æ•°
                'TNX': '^TNX',         # 10å¹´æœŸç¾å€ºæ”¶ç›Šç‡
                'GOLD': 'GC=F',       # é»„é‡‘
                'OIL': 'CL=F',        # åŸæ²¹
            }
            
            for name, symbol in macro_symbols.items():
                try:
                    data = yf.download(symbol, start=self.start_date, end=self.end_date, progress=False)
                    if data is not None and len(data) > 0:
                        if isinstance(data.columns, pd.MultiIndex):
                            data.columns = data.columns.get_level_values(0)
                        macro[name] = data['Close']
                except Exception:
                    pass
        
        if self.verbose:
            print(f"    âœ“ å®è§‚æŒ‡æ ‡: {len(macro)} ä¸ª ({', '.join(macro.keys())})")
        
        return macro
    
    # ==================== é¢æ¿æ•°æ®æ„å»º ====================
    
    def _build_panel_data(self, universe: Dict[str, StockRecord]) -> Optional[pd.DataFrame]:
        """æ„å»ºé¢æ¿æ•°æ®ï¼ˆç”¨äºå› å­è®¡ç®—ï¼‰"""
        if self.verbose:
            print(f"\n  ğŸ”§ æ„å»ºé¢æ¿æ•°æ®...")
        
        panels = []
        for code, stock in universe.items():
            if stock.price_data is None or len(stock.price_data) < 20:
                continue
            
            df = stock.price_data.copy()
            df['stock_code'] = code
            df['stock_name'] = stock.name
            df['industry'] = stock.industry
            
            # è®¡ç®—åŸºç¡€è¡ç”ŸæŒ‡æ ‡
            df['returns'] = df['Close'].pct_change()
            df['log_returns'] = np.log(df['Close'] / df['Close'].shift(1))
            df['turnover'] = df['Volume'] / df['Volume'].rolling(20).mean()
            df['volatility_20d'] = df['returns'].rolling(20).std() * np.sqrt(252)
            df['momentum_20d'] = df['Close'].pct_change(20)
            df['momentum_60d'] = df['Close'].pct_change(60)
            
            panels.append(df)
        
        if panels:
            panel = pd.concat(panels, axis=0)
            panel = panel.reset_index()
            if 'Date' in panel.columns:
                panel = panel.rename(columns={'Date': 'date'})
            elif 'index' in panel.columns:
                panel = panel.rename(columns={'index': 'date'})
            
            if self.verbose:
                print(f"    âœ“ é¢æ¿æ•°æ®: {len(panel)} è¡Œ, {len(panel['stock_code'].unique())} åªè‚¡ç¥¨")
            
            return panel
        
        return None
    
    # ==================== æ•°æ®æ¸…æ´—æ¥å£ ====================
    
    def clean_panel(self, panel: pd.DataFrame, factor_columns: List[str] = None) -> pd.DataFrame:
        """å¯¹é¢æ¿æ•°æ®è¿›è¡Œæ¸…æ´—"""
        return self.cleaner.clean_pipeline(
            panel, columns=factor_columns,
            winsorize_method='mad', fill_method='ffill',
            standardize_method='zscore', by_date=True, date_col='date'
        )
    
    def get_benchmark_returns(self, bundle: UnifiedDataBundle) -> Optional[pd.Series]:
        """è·å–åŸºå‡†æ”¶ç›Šç‡åºåˆ—"""
        if bundle.benchmark_data is not None and 'Close' in bundle.benchmark_data.columns:
            return bundle.benchmark_data['Close'].pct_change().dropna()
        return None


# ==================== ä¾¿æ·å‡½æ•° ====================

def fetch_data(market: str = "US", lookback_years: int = 3, 
               stock_pool: List[str] = None, verbose: bool = True) -> UnifiedDataBundle:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–æŒ‡å®šå¸‚åœºçš„å®Œæ•´æ•°æ®
    
    Args:
        market: å¸‚åœºç±»å‹ ("CN" æˆ– "US")
        lookback_years: å†å²æ•°æ®å›æº¯å¹´æ•°
        stock_pool: æŒ‡å®šè‚¡ç¥¨æ± ï¼ˆå¯é€‰ï¼‰
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        UnifiedDataBundle: ç»Ÿä¸€æ•°æ®åŒ…
    
    ç¤ºä¾‹:
        # è·å–ç¾è‚¡æ•°æ®
        bundle = fetch_data("US")
        
        # è·å–Aè‚¡æ•°æ®
        bundle = fetch_data("CN", lookback_years=3)
        
        # è·å–æŒ‡å®šè‚¡ç¥¨
        bundle = fetch_data("US", stock_pool=["AAPL", "MSFT", "NVDA"])
    """
    layer = UnifiedDataLayer(market=market, lookback_years=lookback_years, verbose=verbose)
    return layer.fetch_all(stock_pool=stock_pool)


if __name__ == "__main__":
    print("=" * 60)
    print("V6.0 ç»Ÿä¸€æ•°æ®å±‚æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ç¾è‚¡æ•°æ®è·å–
    bundle = fetch_data("US", lookback_years=1, stock_pool=["AAPL", "MSFT", "NVDA"])
    
    print(f"\næ•°æ®ç»Ÿè®¡: {bundle.stats}")
    
    if bundle.panel_data is not None:
        print(f"\né¢æ¿æ•°æ®é¢„è§ˆ:")
        print(bundle.panel_data.head())
