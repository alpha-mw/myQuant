#!/usr/bin/env python3
"""
Decision Layer - å†³ç­–å±‚ (ç¬¬6å±‚)

åŠŸèƒ½:
1. å¤šAgentæ¶æ„ - 5ä¸ªä¸“ä¸šåˆ†æå¸ˆAgent
2. LLMå¤šç©ºè¾©è®º - å¯¹å…¬å¸ã€å¸‚åœºã€ç»æµã€äº§å“å¤šç»´åº¦åˆ†æ
3. ç»¼åˆé‡åŒ–åˆ†æ(1-3å±‚) + å®è§‚åˆ†æ(4å±‚) + LLMæ·±åº¦åˆ†æ
4. ç”Ÿæˆå…·ä½“æŠ•èµ„å»ºè®® - ç»„åˆé…ç½®ã€ä¸ªè‚¡ä¹°å–å»ºè®®

Agents:
- è´¢åŠ¡åˆ†æå¸ˆ: åˆ†æè´¢åŠ¡æŠ¥è¡¨ã€ç›ˆåˆ©èƒ½åŠ›ã€ä¼°å€¼
- è¡Œä¸šä¸“å®¶: åˆ†æè¡Œä¸šè¶‹åŠ¿ã€ç«äº‰æ ¼å±€ã€æŠ¤åŸæ²³
- å®è§‚ç»æµå­¦å®¶: åˆ†æç»æµå‘¨æœŸã€æ”¿ç­–å½±å“
- æŠ€æœ¯åˆ†æå¸ˆ: åˆ†æä»·æ ¼èµ°åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡
- é£é™©ç®¡ç†å¸ˆ: è¯„ä¼°é£é™©ã€æå‡ºé£æ§å»ºè®®
"""

import os
import sys
import json
import re
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

import pandas as pd
import numpy as np

# å°è¯•å¯¼å…¥OpenAI

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


class AgentRole(Enum):
    """Agentè§’è‰²"""
    FINANCIAL_ANALYST = "è´¢åŠ¡åˆ†æå¸ˆ"
    INDUSTRY_EXPERT = "è¡Œä¸šä¸“å®¶"
    MACRO_ECONOMIST = "å®è§‚ç»æµå­¦å®¶"
    TECHNICAL_ANALYST = "æŠ€æœ¯åˆ†æå¸ˆ"
    RISK_MANAGER = "é£é™©ç®¡ç†å¸ˆ"


@dataclass
class AgentOpinion:
    """Agentè§‚ç‚¹"""
    role: AgentRole
    bullish_points: List[str] = field(default_factory=list)
    bearish_points: List[str] = field(default_factory=list)
    confidence: float = 0.5
    recommendation: str = ""
    reasoning: str = ""


@dataclass
class StockRecommendation:
    """ä¸ªè‚¡æ¨è"""
    symbol: str
    name: str
    action: str  # BUY, SELL, HOLD
    confidence: float
    target_price: Optional[float] = None
    stop_loss: Optional[float] = None
    reasoning: str = ""
    agent_consensus: Dict[str, str] = field(default_factory=dict)


@dataclass
class PortfolioRecommendation:
    """ç»„åˆæ¨è"""
    total_positions: Dict[str, float]
    cash_ratio: float
    sector_allocation: Dict[str, float]
    risk_level: str
    expected_return: float
    expected_volatility: float
    rebalancing_suggestions: List[str] = field(default_factory=list)


@dataclass
class DecisionLayerResult:
    """å†³ç­–å±‚ç»“æœ"""
    agent_opinions: List[AgentOpinion] = field(default_factory=list)
    debate_summary: str = ""
    stock_recommendations: List[StockRecommendation] = field(default_factory=list)
    portfolio_recommendation: Optional[PortfolioRecommendation] = None
    market_outlook: str = ""
    risk_warnings: List[str] = field(default_factory=list)
    final_report: str = ""


class LLMClient:
    """LLMå®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.environ.get('OPENAI_API_KEY')
        self.client = None
        
        if OPENAI_AVAILABLE and self.api_key:
            self.client = OpenAI(api_key=self.api_key)
    
    def chat(self, messages: List[Dict[str, str]], 
             model: str = "gpt-4",
             temperature: float = 0.7) -> str:
        """è°ƒç”¨LLM"""
        if not self.client:
            return self._mock_response(messages)
        
        try:
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=2000
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"[LLMClient] LLMè°ƒç”¨å¤±è´¥: {e}")
            return self._mock_response(messages)
    
    def _mock_response(self, messages: List[Dict[str, str]]) -> str:
        """æ¨¡æ‹ŸLLMå“åº”ï¼ˆå½“APIä¸å¯ç”¨æ—¶ï¼‰"""
        # æå–ç”¨æˆ·æ¶ˆæ¯
        user_msg = ""
        for msg in messages:
            if msg.get('role') == 'user':
                user_msg = msg.get('content', '')
                break
        
        # æ ¹æ®è§’è‰²è¿”å›æ¨¡æ‹Ÿå“åº”
        if "è´¢åŠ¡åˆ†æå¸ˆ" in user_msg:
            return self._mock_financial_response()
        elif "è¡Œä¸šä¸“å®¶" in user_msg:
            return self._mock_industry_response()
        elif "å®è§‚ç»æµå­¦å®¶" in user_msg:
            return self._mock_macro_response()
        elif "æŠ€æœ¯åˆ†æå¸ˆ" in user_msg:
            return self._mock_technical_response()
        elif "é£é™©ç®¡ç†å¸ˆ" in user_msg:
            return self._mock_risk_response()
        elif "ç»¼åˆæŠ•èµ„å»ºè®®" in user_msg:
            return self._mock_final_response()
        
        return "åŸºäºå½“å‰åˆ†æï¼Œå»ºè®®è°¨æ…æŠ•èµ„ã€‚"
    
    def _mock_financial_response(self) -> str:
        return """{
            "bullish_points": ["ROEç¨³å®šåœ¨15%ä»¥ä¸Š", "ç°é‡‘æµå……è£•", "ä¼°å€¼åˆç†PE<20"],
            "bearish_points": ["æ¯›åˆ©ç‡ç•¥æœ‰ä¸‹æ»‘", "åº”æ”¶è´¦æ¬¾å¢åŠ "],
            "confidence": 0.75,
            "recommendation": "BUY",
            "reasoning": "è´¢åŠ¡æŒ‡æ ‡æ•´ä½“å¥åº·ï¼Œç›ˆåˆ©èƒ½åŠ›ç¨³å®šï¼Œä¼°å€¼æœ‰å¸å¼•åŠ›"
        }"""
    
    def _mock_industry_response(self) -> str:
        return """{
            "bullish_points": ["è¡Œä¸šå¤„äºæˆé•¿æœŸ", "å¸‚åœºä»½é¢é¢†å…ˆ", "æŠ€æœ¯å£å’é«˜"],
            "bearish_points": ["ç«äº‰åŠ å‰§", "æ–°è¿›å…¥è€…å¨èƒ"],
            "confidence": 0.70,
            "recommendation": "BUY",
            "reasoning": "è¡Œä¸šå‰æ™¯è‰¯å¥½ï¼Œå…¬å¸å…·æœ‰æŠ¤åŸæ²³ä¼˜åŠ¿"
        }"""
    
    def _mock_macro_response(self) -> str:
        return """{
            "bullish_points": ["è´§å¸æ”¿ç­–å®½æ¾", "ç»æµå¤è‹", "è¡Œä¸šæ”¿ç­–æ”¯æŒ"],
            "bearish_points": ["é€šèƒ€å‹åŠ›", "åœ°ç¼˜æ”¿æ²»é£é™©"],
            "confidence": 0.65,
            "recommendation": "HOLD",
            "reasoning": "å®è§‚ç¯å¢ƒä¸­æ€§åæ­£é¢ï¼Œä½†éœ€å…³æ³¨é€šèƒ€é£é™©"
        }"""
    
    def _mock_technical_response(self) -> str:
        return """{
            "bullish_points": ["çªç ´å…³é”®é˜»åŠ›ä½", "æˆäº¤é‡æ”¾å¤§", "MACDé‡‘å‰"],
            "bearish_points": ["RSIè¶…ä¹°", "æ¥è¿‘å‰æœŸé«˜ç‚¹"],
            "confidence": 0.60,
            "recommendation": "HOLD",
            "reasoning": "æŠ€æœ¯é¢åå¼ºï¼Œä½†çŸ­æœŸå¯èƒ½å›è°ƒ"
        }"""
    
    def _mock_risk_response(self) -> str:
        return """{
            "bullish_points": ["æ³¢åŠ¨ç‡å¯æ§", "æµåŠ¨æ€§å……è¶³"],
            "bearish_points": ["Betaè¾ƒé«˜", "é›†ä¸­åº¦é£é™©"],
            "confidence": 0.55,
            "recommendation": "CAUTION",
            "reasoning": "é£é™©æ”¶ç›Šæ¯”åˆç†ï¼Œä½†éœ€æ§åˆ¶ä»“ä½"
        }"""
    
    def _mock_final_response(self) -> str:
        return """{
            "market_outlook": "è°¨æ…ä¹è§‚",
            "portfolio_allocation": {
                "AAPL": 0.25,
                "MSFT": 0.25,
                "GOOGL": 0.20,
                "NVDA": 0.15,
                "CASH": 0.15
            },
            "stock_recommendations": [
                {"symbol": "AAPL", "action": "BUY", "confidence": 0.80, "reasoning": "è´¢åŠ¡å¥åº·+è¡Œä¸šé¾™å¤´"},
                {"symbol": "MSFT", "action": "BUY", "confidence": 0.75, "reasoning": "äº‘è®¡ç®—å¢é•¿+AIå¸ƒå±€"},
                {"symbol": "GOOGL", "action": "HOLD", "confidence": 0.65, "reasoning": "ä¼°å€¼åˆç†ä½†å¢é•¿æ”¾ç¼“"}
            ],
            "risk_warnings": ["å…³æ³¨ç¾è”å‚¨æ”¿ç­–", "æ§åˆ¶å•ä¸€è‚¡ç¥¨ä»“ä½<20%"],
            "expected_return": 0.15,
            "expected_volatility": 0.20
        }"""


class DecisionLayer:
    """
    å†³ç­–å±‚ - LLMå¤šAgentå¤šç©ºè¾©è®º
    """
    
    def __init__(self, api_key: Optional[str] = None, verbose: bool = True):
        self.llm = LLMClient(api_key)
        self.verbose = verbose
        self.result = DecisionLayerResult()
    
    def _log(self, msg: str):
        if self.verbose:
            print(f"[DecisionLayer] {msg}")
    
    def _create_agent_prompt(self, role: AgentRole, symbol: str, 
                            quant_data: Dict, macro_data: Dict) -> str:
        """åˆ›å»ºAgentæç¤ºè¯"""
        
        base_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{role.value}ï¼Œéœ€è¦å¯¹è‚¡ç¥¨ {symbol} è¿›è¡Œæ·±å…¥åˆ†æã€‚

ã€é‡åŒ–åˆ†ææ•°æ®ã€‘
- é¢„æµ‹æ”¶ç›Š: {quant_data.get('predicted_return', 'N/A')}
- é¢„æµ‹æ³¢åŠ¨ç‡: {quant_data.get('predicted_volatility', 'N/A')}
- å¤æ™®æ¯”ç‡: {quant_data.get('sharpe_ratio', 'N/A')}
- ä¸»è¦å› å­: {', '.join(quant_data.get('factors', []))}

ã€å®è§‚ç¯å¢ƒã€‘
- å®è§‚ä¿¡å·: {macro_data.get('signal', 'N/A')}
- é£é™©ç­‰çº§: {macro_data.get('risk_level', 'N/A')}

è¯·ä»{role.value}çš„ä¸“ä¸šè§’åº¦ï¼Œåˆ†æè¯¥è‚¡ç¥¨çš„å¤šç©ºå› ç´ ã€‚

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "bullish_points": ["åˆ©å¤šå› ç´ 1", "åˆ©å¤šå› ç´ 2", ...],
    "bearish_points": ["åˆ©ç©ºå› ç´ 1", "åˆ©ç©ºå› ç´ 2", ...],
    "confidence": 0.0-1.0,
    "recommendation": "BUY/SELL/HOLD/CAUTION",
    "reasoning": "è¯¦ç»†åˆ†æç†ç”±"
}}"""
        
        # æ ¹æ®è§’è‰²æ·»åŠ ç‰¹å®šæç¤º
        if role == AgentRole.FINANCIAL_ANALYST:
            base_prompt += """

é‡ç‚¹å…³æ³¨ï¼š
- è´¢åŠ¡æŠ¥è¡¨å¥åº·åº¦ï¼ˆROEã€ROAã€æ¯›åˆ©ç‡ï¼‰
- ä¼°å€¼æ°´å¹³ï¼ˆPEã€PBã€PSï¼‰
- ç°é‡‘æµçŠ¶å†µ
- ç›ˆåˆ©è´¨é‡
"""
        elif role == AgentRole.INDUSTRY_EXPERT:
            base_prompt += """

é‡ç‚¹å…³æ³¨ï¼š
- è¡Œä¸šç”Ÿå‘½å‘¨æœŸï¼ˆæˆé•¿/æˆç†Ÿ/è¡°é€€ï¼‰
- ç«äº‰æ ¼å±€å’Œå¸‚åœºä»½é¢
- æŠ¤åŸæ²³ï¼ˆå“ç‰Œã€æŠ€æœ¯ã€æˆæœ¬ã€ç½‘ç»œæ•ˆåº”ï¼‰
- è¡Œä¸šæ”¿ç­–å½±å“
"""
        elif role == AgentRole.MACRO_ECONOMIST:
            base_prompt += """

é‡ç‚¹å…³æ³¨ï¼š
- ç»æµå‘¨æœŸä½ç½®
- è´§å¸æ”¿ç­–å’Œåˆ©ç‡ç¯å¢ƒ
- é€šèƒ€å½±å“
- æ±‡ç‡é£é™©ï¼ˆå¯¹è·¨å›½å…¬å¸ï¼‰
"""
        elif role == AgentRole.TECHNICAL_ANALYST:
            base_prompt += """

é‡ç‚¹å…³æ³¨ï¼š
- ä»·æ ¼è¶‹åŠ¿ï¼ˆåŠ¨é‡ã€åè½¬ï¼‰
- æ”¯æ’‘é˜»åŠ›ä½
- æˆäº¤é‡å˜åŒ–
- æŠ€æœ¯æŒ‡æ ‡ä¿¡å·ï¼ˆRSIã€MACDã€å¸ƒæ—å¸¦ï¼‰
"""
        elif role == AgentRole.RISK_MANAGER:
            base_prompt += """

é‡ç‚¹å…³æ³¨ï¼š
- æ³¢åŠ¨ç‡å’Œæœ€å¤§å›æ’¤
- Betaå’Œç³»ç»Ÿæ€§é£é™©
- æµåŠ¨æ€§é£é™©
- é›†ä¸­åº¦é£é™©
- å°¾éƒ¨é£é™©
"""
        
        return base_prompt
    
    def _parse_agent_response(self, response: str, role: AgentRole) -> AgentOpinion:
        """è§£æAgentå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                
                return AgentOpinion(
                    role=role,
                    bullish_points=data.get('bullish_points', []),
                    bearish_points=data.get('bearish_points', []),
                    confidence=data.get('confidence', 0.5),
                    recommendation=data.get('recommendation', 'HOLD'),
                    reasoning=data.get('reasoning', '')
                )
        except Exception as e:
            self._log(f"è§£æAgentå“åº”å¤±è´¥: {e}")
        
        # è¿”å›é»˜è®¤è§‚ç‚¹
        return AgentOpinion(role=role)
    
    def run_agent_analysis(self, symbol: str, quant_data: Dict, 
                          macro_data: Dict) -> List[AgentOpinion]:
        """
        è¿è¡Œå¤šAgentåˆ†æ
        """
        self._log(f"å¼€å§‹å¤šAgentåˆ†æ: {symbol}")
        
        opinions = []
        
        for role in AgentRole:
            self._log(f"  è¿è¡Œ {role.value}...")
            
            prompt = self._create_agent_prompt(role, symbol, quant_data, macro_data)
            
            messages = [
                {"role": "system", "content": f"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{role.value}ï¼Œæ“…é•¿æŠ•èµ„åˆ†æã€‚è¯·åŸºäºæä¾›çš„æ•°æ®ç»™å‡ºå®¢è§‚åˆ†æã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            response = self.llm.chat(messages)
            opinion = self._parse_agent_response(response, role)
            opinions.append(opinion)
            
            self._log(f"    {role.value}: {opinion.recommendation} (ç½®ä¿¡åº¦{opinion.confidence:.0%})")
        
        return opinions
    
    def debate_and_consensus(self, opinions: List[AgentOpinion], 
                            symbol: str) -> StockRecommendation:
        """
        Agentè¾©è®ºå¹¶è¾¾æˆå…±è¯†
        """
        self._log(f"Agentè¾©è®º: {symbol}")
        
        # ç»Ÿè®¡è§‚ç‚¹
        recommendations = [op.recommendation for op in opinions]
        buy_count = recommendations.count('BUY')
        sell_count = recommendations.count('SELL')
        hold_count = recommendations.count('HOLD')
        
        # è®¡ç®—åŠ æƒç½®ä¿¡åº¦
        total_confidence = sum(op.confidence for op in opinions)
        avg_confidence = total_confidence / len(opinions) if opinions else 0
        
        # ç¡®å®šæœ€ç»ˆå»ºè®®
        if buy_count >= 3:
            final_action = "BUY"
        elif sell_count >= 3:
            final_action = "SELL"
        else:
            final_action = "HOLD"
        
        # ç”Ÿæˆç†ç”±
        all_bullish = []
        all_bearish = []
        for op in opinions:
            all_bullish.extend(op.bullish_points)
            all_bearish.extend(op.bearish_points)
        
        reasoning = f"çœ‹å¤šå› ç´ ({len(all_bullish)}æ¡): " + "; ".join(all_bullish[:3])
        reasoning += f" | çœ‹ç©ºå› ç´ ({len(all_bearish)}æ¡): " + "; ".join(all_bearish[:3])
        
        # Agentå…±è¯†è®°å½•
        consensus = {op.role.value: op.recommendation for op in opinions}
        
        return StockRecommendation(
            symbol=symbol,
            name=symbol,
            action=final_action,
            confidence=avg_confidence,
            reasoning=reasoning,
            agent_consensus=consensus
        )
    
    def generate_portfolio_recommendation(
        self,
        stock_recommendations: List[StockRecommendation],
        quant_results: Dict,
        macro_signal: str,
        risk_result: Dict
    ) -> PortfolioRecommendation:
        """
        ç”Ÿæˆç»„åˆæ¨è
        """
        self._log("ç”Ÿæˆç»„åˆæ¨è...")
        
        # åŸºäºå®è§‚ä¿¡å·ç¡®å®šåŸºç¡€ä»“ä½
        base_allocation = {
            "ğŸ”´": 0.3,
            "ğŸŸ¡": 0.5,
            "ğŸŸ¢": 0.8,
            "ğŸ”µ": 1.0
        }.get(macro_signal, 0.5)
        
        # ç­›é€‰BUYæ¨è
        buy_stocks = [s for s in stock_recommendations if s.action == "BUY"]
        
        # ç­‰æƒé‡åˆ†é…
        positions = {}
        if buy_stocks:
            weight_per_stock = base_allocation / len(buy_stocks)
            for stock in buy_stocks:
                positions[stock.symbol] = min(weight_per_stock, 0.2)  # å•ç¥¨ä¸è¶…è¿‡20%
        
        # é‡æ–°å½’ä¸€åŒ–
        total = sum(positions.values())
        if total > 0:
            positions = {k: v/total * base_allocation for k, v in positions.items()}
        
        cash_ratio = 1 - sum(positions.values())
        
        return PortfolioRecommendation(
            total_positions=positions,
            cash_ratio=cash_ratio,
            sector_allocation={},  # ç®€åŒ–
            risk_level=risk_result.get('risk_level', 'normal'),
            expected_return=quant_results.get('expected_return', 0.1),
            expected_volatility=quant_results.get('expected_volatility', 0.2),
            rebalancing_suggestions=["å®šæœŸå†å¹³è¡¡", "å…³æ³¨é£é™©ä¿¡å·å˜åŒ–"]
        )
    
    def run_decision_process(
        self,
        symbols: List[str],
        quant_data: Dict[str, Dict],
        macro_data: Dict,
        risk_data: Dict
    ) -> DecisionLayerResult:
        """
        è¿è¡Œå®Œæ•´å†³ç­–æµç¨‹
        """
        self._log("=" * 80)
        self._log("ã€ç¬¬6å±‚ã€‘å†³ç­–å±‚ - LLMå¤šAgentå¤šç©ºè¾©è®º")
        self._log("=" * 80)
        
        result = DecisionLayerResult()
        
        # 1. å¤šAgentåˆ†ææ¯åªè‚¡ç¥¨
        stock_recommendations = []
        
        for symbol in symbols:
            self._log(f"\nåˆ†æè‚¡ç¥¨: {symbol}")
            
            # è·å–è¯¥è‚¡ç¥¨çš„é‡åŒ–æ•°æ®
            symbol_quant = quant_data.get(symbol, {})
            
            # è¿è¡ŒAgentåˆ†æ
            opinions = self.run_agent_analysis(symbol, symbol_quant, macro_data)
            result.agent_opinions.extend(opinions)
            
            # Agentè¾©è®ºè¾¾æˆå…±è¯†
            stock_rec = self.debate_and_consensus(opinions, symbol)
            stock_recommendations.append(stock_rec)
            
            self._log(f"æœ€ç»ˆå»ºè®®: {stock_rec.action} (ç½®ä¿¡åº¦{stock_rec.confidence:.0%})")
        
        result.stock_recommendations = stock_recommendations
        
        # 2. ç”Ÿæˆç»„åˆæ¨è
        result.portfolio_recommendation = self.generate_portfolio_recommendation(
            stock_recommendations,
            quant_data,
            macro_data.get('signal', 'ğŸŸ¡'),
            risk_data
        )
        
        # 3. ç”Ÿæˆå¸‚åœºå±•æœ›
        buy_count = sum(1 for s in stock_recommendations if s.action == "BUY")
        sell_count = sum(1 for s in stock_recommendations if s.action == "SELL")
        
        if buy_count > sell_count:
            result.market_outlook = "ç»“æ„æ€§æœºä¼šï¼Œç²¾é€‰ä¸ªè‚¡"
        elif sell_count > buy_count:
            result.market_outlook = "é˜²å¾¡ä¸ºä¸»ï¼Œé™ä½ä»“ä½"
        else:
            result.market_outlook = "éœ‡è¡å¸‚ï¼Œå‡è¡¡é…ç½®"
        
        # 4. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        result.final_report = self._generate_final_report(result)
        
        self._log("\nå†³ç­–å±‚å®Œæˆ")
        
        return result
    
    def _generate_final_report(self, result: DecisionLayerResult) -> str:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        lines = []
        
        lines.append("# æŠ•èµ„å†³ç­–æŠ¥å‘Š")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # å¸‚åœºå±•æœ›
        lines.append("## ğŸ“Š å¸‚åœºå±•æœ›")
        lines.append(result.market_outlook)
        lines.append("")
        
        # ä¸ªè‚¡æ¨è
        lines.append("## ğŸ“ˆ ä¸ªè‚¡æ¨è")
        lines.append("")
        lines.append("| è‚¡ç¥¨ | å»ºè®® | ç½®ä¿¡åº¦ | ç†ç”± |")
        lines.append("|:---|:---:|:---:|:---|")
        for rec in result.stock_recommendations:
            action_emoji = {"BUY": "ğŸŸ¢", "SELL": "ğŸ”´", "HOLD": "ğŸŸ¡"}.get(rec.action, "âšª")
            lines.append(f"| {rec.symbol} | {action_emoji} {rec.action} | {rec.confidence:.0%} | {rec.reasoning[:50]}... |")
        lines.append("")
        
        # ç»„åˆé…ç½®
        if result.portfolio_recommendation:
            lines.append("## ğŸ’¼ ç»„åˆé…ç½®")
            lines.append("")
            lines.append("**æŒä»“å»ºè®®**:")
            for symbol, weight in sorted(
                result.portfolio_recommendation.total_positions.items(),
                key=lambda x: x[1],
                reverse=True
            ):
                lines.append(f"- {symbol}: {weight:.1%}")
            lines.append(f"- ç°é‡‘: {result.portfolio_recommendation.cash_ratio:.1%}")
            lines.append("")
            lines.append(f"**é¢„æœŸæ”¶ç›Š**: {result.portfolio_recommendation.expected_return:.1%}")
            lines.append(f"**é¢„æœŸæ³¢åŠ¨**: {result.portfolio_recommendation.expected_volatility:.1%}")
            lines.append("")
        
        # Agentå…±è¯†
        lines.append("## ğŸ¤– Agentå…±è¯†")
        lines.append("")
        for rec in result.stock_recommendations[:3]:
            lines.append(f"**{rec.symbol}**:")
            for agent, action in rec.agent_consensus.items():
                lines.append(f"  - {agent}: {action}")
            lines.append("")
        
        return "\n".join(lines)


# ==================== æµ‹è¯• ====================

if __name__ == '__main__':
    print("=" * 80)
    print("Decision Layer - æµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºå†³ç­–å±‚
    decision_layer = DecisionLayer(verbose=True)
    
    # æµ‹è¯•æ•°æ®
    symbols = ["AAPL", "MSFT", "GOOGL"]
    
    quant_data = {
        "AAPL": {"predicted_return": 0.15, "predicted_volatility": 0.25, "sharpe_ratio": 1.2, "factors": ["momentum", "value"]},
        "MSFT": {"predicted_return": 0.12, "predicted_volatility": 0.22, "sharpe_ratio": 1.1, "factors": ["quality", "growth"]},
        "GOOGL": {"predicted_return": 0.08, "predicted_volatility": 0.28, "sharpe_ratio": 0.8, "factors": ["value"]}
    }
    
    macro_data = {"signal": "ğŸŸ¡", "risk_level": "ä¸­é£é™©"}
    risk_data = {"risk_level": "normal"}
    
    # è¿è¡Œå†³ç­–æµç¨‹
    result = decision_layer.run_decision_process(
        symbols=symbols,
        quant_data=quant_data,
        macro_data=macro_data,
        risk_data=risk_data
    )
    
    print("\n" + "=" * 80)
    print("æœ€ç»ˆæŠ¥å‘Š")
    print("=" * 80)
    print(result.final_report)
