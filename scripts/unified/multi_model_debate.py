#!/usr/bin/env python3
"""
Multi-Model Debate System - å¤šæ¨¡å‹å¤šç©ºè¾©è®ºç³»ç»Ÿ

ç¬¬6å±‚å†³ç­–å±‚çš„æ ¸å¿ƒç»„ä»¶

åŠŸèƒ½:
1. å¤šæ¨¡å‹æ¶æ„ - 5ä¸ªä¸“ä¸šåˆ†ææ¨¡å‹
2. å¤šç©ºè¾©è®º - æ¯ä¸ªæ¨¡å‹åˆ†åˆ«è¾“å‡ºçœ‹å¤š/çœ‹ç©ºè§‚ç‚¹
3. æ·±åº¦ç ”ç©¶ - å…¬å¸åŸºæœ¬é¢ã€äº§å“ã€ç«äº‰æ ¼å±€ã€è¡Œä¸šè¶‹åŠ¿
4. ç»¼åˆåˆ¤æ–­ - æ•´åˆ1-5å±‚æ‰€æœ‰ä¿¡æ¯ç”ŸæˆæŠ•èµ„å†³ç­–

åˆ†æç»´åº¦:
- è´¢åŠ¡æ¨¡å‹: è´¢åŠ¡æŠ¥è¡¨ã€ç›ˆåˆ©èƒ½åŠ›ã€ä¼°å€¼ã€ç°é‡‘æµ
- è¡Œä¸šæ¨¡å‹: è¡Œä¸šç”Ÿå‘½å‘¨æœŸã€ç«äº‰æ ¼å±€ã€æŠ¤åŸæ²³ã€æ”¿ç­–
- å®è§‚æ¨¡å‹: ç»æµå‘¨æœŸã€è´§å¸æ”¿ç­–ã€é€šèƒ€ã€åœ°ç¼˜æ”¿æ²»
- æŠ€æœ¯æ¨¡å‹: ä»·æ ¼è¶‹åŠ¿ã€æŠ€æœ¯æŒ‡æ ‡ã€é‡ä»·å…³ç³»ã€å¸‚åœºæƒ…ç»ª
- é£é™©æ¨¡å‹: æ³¢åŠ¨ç‡ã€å›æ’¤ã€æµåŠ¨æ€§ã€å°¾éƒ¨é£é™©ã€é›†ä¸­åº¦
"""

import os
import json
import re
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

import pandas as pd
import numpy as np

# å°è¯•å¯¼å…¥å¤šä¸ªLLM

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


class AnalystModel(Enum):
    """åˆ†ææ¨¡å‹ç±»å‹"""
    FINANCIAL = "è´¢åŠ¡åˆ†ææ¨¡å‹"
    INDUSTRY = "è¡Œä¸šç ”ç©¶æ¨¡å‹"
    MACRO = "å®è§‚åˆ†ææ¨¡å‹"
    TECHNICAL = "æŠ€æœ¯åˆ†ææ¨¡å‹"
    RISK = "é£é™©è¯„ä¼°æ¨¡å‹"


@dataclass
class DebateArgument:
    """è¾©è®ºè§‚ç‚¹"""
    model: AnalystModel
    side: str  # "bullish" or "bearish"
    points: List[str]
    confidence: float
    evidence: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ModelAnalysis:
    """å•ä¸ªæ¨¡å‹åˆ†æç»“æœ"""
    model: AnalystModel
    bullish_arguments: List[DebateArgument]
    bearish_arguments: List[DebateArgument]
    overall_bias: str  # "bullish", "bearish", "neutral"
    confidence: float
    key_factors: List[str]
    reasoning: str


@dataclass
class InvestmentDecision:
    """æŠ•èµ„å†³ç­–"""
    symbol: str
    decision: str  # "å¼ºçƒˆä¹°å…¥", "ä¹°å…¥", "æŒæœ‰", "å–å‡º", "å¼ºçƒˆå–å‡º"
    confidence: float
    position_size: float  # å»ºè®®ä»“ä½ 0-1
    target_price: Optional[float]
    stop_loss: Optional[float]
    time_horizon: str  # "çŸ­æœŸ", "ä¸­æœŸ", "é•¿æœŸ"
    
    # å†³ç­–é€»è¾‘
    logic_chain: List[str] = field(default_factory=list)
    supporting_evidence: List[str] = field(default_factory=list)
    opposing_concerns: List[str] = field(default_factory=list)
    risk_mitigation: List[str] = field(default_factory=list)
    
    # æ¨¡å‹å…±è¯†
    model_consensus: Dict[str, str] = field(default_factory=dict)
    model_confidences: Dict[str, float] = field(default_factory=dict)


@dataclass
class DebateResult:
    """è¾©è®ºç»“æœ"""
    symbol: str
    company_research: Dict[str, Any]  # å…¬å¸æ·±åº¦ç ”ç©¶
    model_analyses: List[ModelAnalysis]
    debate_summary: str
    investment_decision: InvestmentDecision
    portfolio_suggestion: Dict[str, Any]
    risk_assessment: Dict[str, Any]
    final_report: str


class LLMProvider:
    """LLMæä¾›å•†"""
    
    def __init__(self):
        self.openai_key = os.environ.get('OPENAI_API_KEY')
        self.deepseek_key = os.environ.get('DEEPSEEK_API_KEY')
        self.client = None
        
        if OPENAI_AVAILABLE and self.openai_key:
            self.client = OpenAI(api_key=self.openai_key)
    
    def call(self, prompt: str, model: str = "gpt-4", temperature: float = 0.7) -> str:
        """è°ƒç”¨LLM"""
        if self.client:
            try:
                response = self.client.chat.completions.create(
                    model=model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=temperature,
                    max_tokens=2500
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"[LLM] APIè°ƒç”¨å¤±è´¥: {e}")
        
        return self._mock_response(prompt)
    
    def _mock_response(self, prompt: str) -> str:
        """æ¨¡æ‹Ÿå“åº”"""
        if "è´¢åŠ¡åˆ†æ" in prompt:
            return self._mock_financial()
        elif "è¡Œä¸šç ”ç©¶" in prompt:
            return self._mock_industry()
        elif "å®è§‚åˆ†æ" in prompt:
            return self._mock_macro()
        elif "æŠ€æœ¯åˆ†æ" in prompt:
            return self._mock_technical()
        elif "é£é™©è¯„ä¼°" in prompt:
            return self._mock_risk()
        elif "ç»¼åˆå†³ç­–" in prompt:
            return self._mock_final()
        return "{}"
    
    def _mock_financial(self) -> str:
        return json.dumps({
            "bullish_points": [
                "ROEè¿ç»­3å¹´ä¿æŒåœ¨18%ä»¥ä¸Šï¼Œç›ˆåˆ©èƒ½åŠ›ç¨³å®š",
                "è‡ªç”±ç°é‡‘æµå……è£•ï¼ŒFCF/è¥æ”¶æ¯”ä¾‹è¾¾15%",
                "å½“å‰PE 15å€ï¼Œä½äºè¡Œä¸šå¹³å‡20å€ï¼Œä¼°å€¼æœ‰å¸å¼•åŠ›",
                "æ¯›åˆ©ç‡35%ï¼Œå‡€åˆ©ç‡12%ï¼Œç›ˆåˆ©è´¨é‡ä¼˜ç§€"
            ],
            "bearish_points": [
                "åº”æ”¶è´¦æ¬¾å‘¨è½¬å¤©æ•°ä»45å¤©å¢è‡³60å¤©ï¼Œå›æ¬¾å‹åŠ›å¢å¤§",
                "èµ„æœ¬æ”¯å‡ºå è¥æ”¶æ¯”ä¾‹ä¸Šå‡è‡³20%ï¼Œå½±å“ç°é‡‘æµ",
                "å­˜è´§å‘¨è½¬ç‡ä¸‹é™ï¼Œå¯èƒ½å­˜åœ¨åº“å­˜ç§¯å‹"
            ],
            "confidence": 0.75,
            "bias": "bullish",
            "key_factors": ["ROEç¨³å®šæ€§", "ç°é‡‘æµè´¨é‡", "ä¼°å€¼æ°´å¹³"],
            "reasoning": "è´¢åŠ¡æŒ‡æ ‡æ•´ä½“å¥åº·ï¼Œä¼°å€¼åˆç†ï¼Œç›ˆåˆ©èƒ½åŠ›å¼º"
        }, ensure_ascii=False)
    
    def _mock_industry(self) -> str:
        return json.dumps({
            "bullish_points": [
                "è¡Œä¸šå¤„äºæˆé•¿æœŸï¼Œæœªæ¥3å¹´CAGRé¢„è®¡15%",
                "å…¬å¸åœ¨ç»†åˆ†å¸‚åœºå æœ‰ç‡è¾¾30%ï¼Œé¾™å¤´åœ°ä½ç¨³å›º",
                "æŠ€æœ¯å£å’é«˜ï¼Œç ”å‘æŠ•å…¥å æ¯”8%ï¼Œä¸“åˆ©æ•°é‡é¢†å…ˆ",
                "æ”¿ç­–æ”¯æŒåŠ›åº¦å¤§ï¼Œå±äºå›½å®¶æˆ˜ç•¥æ€§æ–°å…´äº§ä¸š"
            ],
            "bearish_points": [
                "æ–°è¿›å…¥è€…å¢å¤šï¼Œç«äº‰åŠ å‰§ï¼Œä»·æ ¼æˆ˜é£é™©",
                "ä¸Šæ¸¸åŸææ–™ä»·æ ¼æ³¢åŠ¨å¤§ï¼Œæˆæœ¬æ§åˆ¶å‹åŠ›",
                "æŠ€æœ¯è¿­ä»£å¿«ï¼Œéœ€æŒç»­é«˜ç ”å‘æŠ•å…¥ç»´æŒç«äº‰åŠ›"
            ],
            "confidence": 0.70,
            "bias": "bullish",
            "key_factors": ["è¡Œä¸šæˆé•¿æ€§", "å¸‚åœºä»½é¢", "æŠ€æœ¯å£å’", "æ”¿ç­–æ”¯æŒ"],
            "reasoning": "è¡Œä¸šå‰æ™¯è‰¯å¥½ï¼Œå…¬å¸å…·æœ‰æ˜æ˜¾ç«äº‰ä¼˜åŠ¿å’Œæ”¿ç­–çº¢åˆ©"
        }, ensure_ascii=False)
    
    def _mock_macro(self) -> str:
        return json.dumps({
            "bullish_points": [
                "è´§å¸æ”¿ç­–å®½æ¾ï¼ŒæµåŠ¨æ€§å……è£•åˆ©å¥½è‚¡å¸‚",
                "ç»æµå¤è‹æ€åŠ¿æ˜ç¡®ï¼ŒPMIè¿ç»­3ä¸ªæœˆæ‰©å¼ ",
                "è¡Œä¸šå—ç›Šäºç¨³å¢é•¿æ”¿ç­–ï¼ŒåŸºå»ºæŠ•èµ„åŠ ç "
            ],
            "bearish_points": [
                "é€šèƒ€å‹åŠ›ä¸Šå‡ï¼ŒCPIæ¥è¿‘3%è­¦æˆ’çº¿",
                "ç¾è”å‚¨å¯èƒ½åŠ æ¯ï¼Œå¤–èµ„æµå‡ºå‹åŠ›",
                "åœ°ç¼˜æ”¿æ²»é£é™©ï¼Œè´¸æ˜“æ‘©æ“¦ä¸ç¡®å®šæ€§"
            ],
            "confidence": 0.65,
            "bias": "neutral",
            "key_factors": ["è´§å¸æ”¿ç­–", "ç»æµå‘¨æœŸ", "é€šèƒ€å‹åŠ›"],
            "reasoning": "å®è§‚ç¯å¢ƒä¸­æ€§åæ­£é¢ï¼Œä½†éœ€å…³æ³¨é€šèƒ€å’Œå¤–éƒ¨é£é™©"
        }, ensure_ascii=False)
    
    def _mock_technical(self) -> str:
        return json.dumps({
            "bullish_points": [
                "è‚¡ä»·çªç ´å‰æœŸé«˜ç‚¹ï¼Œå½¢æˆä¸Šå‡è¶‹åŠ¿",
                "æˆäº¤é‡æ”¾å¤§ï¼Œèµ„é‡‘æµå…¥æ˜æ˜¾",
                "MACDé‡‘å‰ï¼ŒRSIåœ¨50-70å¥åº·åŒºé—´",
                "å‡çº¿å¤šå¤´æ’åˆ—ï¼ŒçŸ­æœŸ>ä¸­æœŸ>é•¿æœŸ"
            ],
            "bearish_points": [
                "è‚¡ä»·æ¥è¿‘å†å²é«˜ä½ï¼Œé˜»åŠ›è¾ƒå¤§",
                "RSIæ¥è¿‘70ï¼ŒçŸ­æœŸå¯èƒ½è¶…ä¹°å›è°ƒ",
                "æ³¢åŠ¨ç‡ä¸Šå‡ï¼Œéœ€è­¦æƒ•å‰§çƒˆæ³¢åŠ¨"
            ],
            "confidence": 0.60,
            "bias": "bullish",
            "key_factors": ["è¶‹åŠ¿æ–¹å‘", "æˆäº¤é‡", "æŠ€æœ¯æŒ‡æ ‡"],
            "reasoning": "æŠ€æœ¯é¢åå¼ºï¼Œä¸Šå‡è¶‹åŠ¿ç¡®ç«‹ï¼Œä½†çŸ­æœŸæ³¨æ„å›è°ƒé£é™©"
        }, ensure_ascii=False)
    
    def _mock_risk(self) -> str:
        return json.dumps({
            "bullish_points": [
                "æ³¢åŠ¨ç‡20%ï¼Œå¤„äºå¯æ§èŒƒå›´",
                "æµåŠ¨æ€§å……è¶³ï¼Œæ—¥å‡æˆäº¤é¢5äº¿ä»¥ä¸Š",
                "Beta 0.9ï¼Œç³»ç»Ÿæ€§é£é™©é€‚ä¸­"
            ],
            "bearish_points": [
                "æœ€å¤§å›æ’¤å¯èƒ½è¾¾25%ï¼Œéœ€è®¾ç½®æ­¢æŸ",
                "è¡Œä¸šé›†ä¸­åº¦é«˜ï¼Œå•ä¸€è¡Œä¸šé£é™©",
                "å°¾éƒ¨é£é™©ï¼šæ”¿ç­–å˜åŒ–å¯èƒ½å¸¦æ¥å†²å‡»"
            ],
            "confidence": 0.65,
            "bias": "caution",
            "key_factors": ["æ³¢åŠ¨ç‡", "å›æ’¤é£é™©", "æµåŠ¨æ€§"],
            "reasoning": "é£é™©æ”¶ç›Šæ¯”åˆç†ï¼Œä½†éœ€æ§åˆ¶ä»“ä½å’Œè®¾ç½®æ­¢æŸ"
        }, ensure_ascii=False)
    
    def _mock_final(self) -> str:
        return json.dumps({
            "decision": "ä¹°å…¥",
            "confidence": 0.72,
            "position_size": 0.15,
            "target_price": 150.0,
            "stop_loss": 120.0,
            "time_horizon": "ä¸­æœŸ",
            "logic_chain": [
                "è´¢åŠ¡æŒ‡æ ‡å¥åº·ï¼ŒROE 18%ï¼Œä¼°å€¼åˆç†PE 15å€",
                "è¡Œä¸šå¤„äºæˆé•¿æœŸï¼Œå…¬å¸å¸‚å ç‡30%é¾™å¤´åœ°ä½",
                "å®è§‚ç¯å¢ƒä¸­æ€§åæ­£é¢ï¼Œæ”¿ç­–æ”¯æŒ",
                "æŠ€æœ¯é¢ä¸Šå‡è¶‹åŠ¿ç¡®ç«‹ï¼Œèµ„é‡‘æµå…¥",
                "é£é™©å¯æ§ï¼Œè®¾ç½®æ­¢æŸä½ä¿æŠ¤"
            ],
            "supporting_evidence": [
                "è¿ç»­3å¹´ROE>18%",
                "è¡Œä¸šCAGR 15%",
                "çªç ´å‰æœŸé«˜ç‚¹"
            ],
            "opposing_concerns": [
                "åº”æ”¶è´¦æ¬¾å¢åŠ ",
                "ç«äº‰åŠ å‰§",
                "çŸ­æœŸå¯èƒ½è¶…ä¹°"
            ],
            "risk_mitigation": [
                "ä»“ä½æ§åˆ¶åœ¨15%ä»¥å†…",
                "è®¾ç½®æ­¢æŸä½120å…ƒ",
                "å®šæœŸè·Ÿè¸ªè´¢åŠ¡å˜åŒ–"
            ]
        }, ensure_ascii=False)


class MultiModelDebateSystem:
    """
    å¤šæ¨¡å‹å¤šç©ºè¾©è®ºç³»ç»Ÿ
    """
    
    def __init__(self, verbose: bool = True):
        self.llm = LLMProvider()
        self.verbose = verbose
    
    def _log(self, msg: str):
        if self.verbose:
            print(f"[DebateSystem] {msg}")
    
    def _create_company_research_prompt(self, symbol: str, 
                                       quant_data: Dict,
                                       macro_data: Dict) -> str:
        """åˆ›å»ºå…¬å¸æ·±åº¦ç ”ç©¶æç¤ºè¯"""
        return f"""è¯·å¯¹è‚¡ç¥¨ {symbol} è¿›è¡Œå…¨é¢çš„å…¬å¸æ·±åº¦ç ”ç©¶ï¼ŒåŒ…æ‹¬ï¼š

ã€é‡åŒ–æ•°æ®å‚è€ƒã€‘
- é¢„æµ‹æ”¶ç›Š: {quant_data.get('predicted_return', 'N/A')}
- å¤æ™®æ¯”ç‡: {quant_data.get('sharpe_ratio', 'N/A')}
- ä¸»è¦å› å­: {', '.join(quant_data.get('factors', []))}

ã€å®è§‚ç¯å¢ƒã€‘
- å®è§‚ä¿¡å·: {macro_data.get('signal', 'N/A')}
- é£é™©ç­‰çº§: {macro_data.get('risk_level', 'N/A')}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š
1. å…¬å¸æ¦‚å†µ: ä¸»è¥ä¸šåŠ¡ã€å•†ä¸šæ¨¡å¼ã€æ ¸å¿ƒç«äº‰åŠ›
2. äº§å“åˆ†æ: äº§å“çº¿ã€æŠ€æœ¯å£å’ã€ç ”å‘æŠ•å…¥ã€ä¸“åˆ©æƒ…å†µ
3. ç«äº‰æ ¼å±€: å¸‚åœºä»½é¢ã€ä¸»è¦ç«äº‰å¯¹æ‰‹ã€ç«äº‰ä¼˜åŠ¿/åŠ£åŠ¿
4. è¡Œä¸šè¶‹åŠ¿: è¡Œä¸šç”Ÿå‘½å‘¨æœŸã€å¸‚åœºè§„æ¨¡ã€å¢é•¿ç‡ã€æ”¿ç­–æ”¯æŒ
5. ç«äº‰å¯¹æ‰‹: ä¸»è¦ç«äº‰å¯¹æ‰‹çš„å‘å±•æƒ…å†µã€å·®å¼‚åŒ–ç­–ç•¥
6. è´¢åŠ¡å¥åº·: ç›ˆåˆ©èƒ½åŠ›ã€æˆé•¿æ€§ã€ç°é‡‘æµã€å¿å€ºèƒ½åŠ›

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç ”ç©¶ç»“æœï¼š
{{
    "company_overview": "å…¬å¸æ¦‚å†µ",
    "products": {{"main_products": [], "tech_moat": "", "rd_investment": ""}},
    "competition": {{"market_share": "", "main_competitors": [], "advantages": [], "disadvantages": []}},
    "industry": {{"lifecycle": "", "market_size": "", "growth_rate": "", "policy_support": ""}},
    "competitor_analysis": {{"key_competitors": [], "their_strategies": [], "our_differentiation": ""}},
    "financial_health": {{"profitability": "", "growth": "", "cashflow": "", "debt": ""}}
}}"""
    
    def _create_model_prompt(self, model: AnalystModel, symbol: str,
                            company_research: Dict,
                            quant_data: Dict,
                            macro_data: Dict,
                            risk_data: Dict) -> str:
        """åˆ›å»ºå•ä¸ªæ¨¡å‹çš„åˆ†ææç¤ºè¯"""
        
        base = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{model.value}åˆ†æå¸ˆï¼Œéœ€è¦å¯¹è‚¡ç¥¨ {symbol} è¿›è¡Œæ·±å…¥åˆ†æã€‚

ã€å…¬å¸æ·±åº¦ç ”ç©¶ã€‘
{json.dumps(company_research, ensure_ascii=False, indent=2)[:1000]}

ã€é‡åŒ–åˆ†ææ•°æ®ã€‘
- é¢„æµ‹æ”¶ç›Š: {quant_data.get('predicted_return', 'N/A')}
- é¢„æµ‹æ³¢åŠ¨ç‡: {quant_data.get('predicted_volatility', 'N/A')}
- å¤æ™®æ¯”ç‡: {quant_data.get('sharpe_ratio', 'N/A')}
- ä¸»è¦å› å­: {', '.join(quant_data.get('factors', []))}

ã€å®è§‚ç¯å¢ƒã€‘
- å®è§‚ä¿¡å·: {macro_data.get('signal', 'N/A')}
- é£é™©ç­‰çº§: {macro_data.get('risk_level', 'N/A')}

ã€é£æ§æ•°æ®ã€‘
- é£é™©ç­‰çº§: {risk_data.get('risk_level', 'N/A')}
- æ³¢åŠ¨ç‡: {risk_data.get('volatility', 'N/A')}

è¯·ä»{model.value}çš„ä¸“ä¸šè§’åº¦ï¼Œåˆ†åˆ«åˆ—å‡ºçœ‹å¤šå’Œçœ‹ç©ºçš„ç†ç”±ã€‚"""
        
        # æ ¹æ®æ¨¡å‹ç±»å‹æ·»åŠ ç‰¹å®šåˆ†æè¦æ±‚
        specifics = {
            AnalystModel.FINANCIAL: """
é‡ç‚¹å…³æ³¨ï¼š
- è´¢åŠ¡æŠ¥è¡¨å¥åº·åº¦ï¼ˆROEã€ROAã€ROICã€æ¯›åˆ©ç‡ã€å‡€åˆ©ç‡ï¼‰
- ä¼°å€¼æ°´å¹³ï¼ˆPEã€PBã€PSã€EV/EBITDAã€PEGï¼‰
- ç°é‡‘æµçŠ¶å†µï¼ˆç»è¥ç°é‡‘æµã€è‡ªç”±ç°é‡‘æµã€ç°é‡‘æµè´¨é‡ï¼‰
- ç›ˆåˆ©è´¨é‡ï¼ˆåº”æ”¶è´¦æ¬¾ã€å­˜è´§ã€èµ„æœ¬æ”¯å‡ºã€ç›ˆåˆ©å¯æŒç»­æ€§ï¼‰
- æˆé•¿æ€§ï¼ˆè¥æ”¶å¢é•¿ã€åˆ©æ¶¦å¢é•¿ã€å¢é•¿è´¨é‡ï¼‰
""",
            AnalystModel.INDUSTRY: """
é‡ç‚¹å…³æ³¨ï¼š
- è¡Œä¸šç”Ÿå‘½å‘¨æœŸï¼ˆå¯¼å…¥/æˆé•¿/æˆç†Ÿ/è¡°é€€ï¼‰
- å¸‚åœºè§„æ¨¡å’Œå¢é•¿ç‡ï¼ˆTAMã€SAMã€SOMï¼‰
- ç«äº‰æ ¼å±€ï¼ˆCR5ã€HHIæŒ‡æ•°ã€ç«äº‰å¼ºåº¦ï¼‰
- æŠ¤åŸæ²³ï¼ˆå“ç‰Œã€æŠ€æœ¯ã€æˆæœ¬ã€ç½‘ç»œæ•ˆåº”ã€è½¬æ¢æˆæœ¬ï¼‰
- æ”¿ç­–æ”¯æŒï¼ˆäº§ä¸šæ”¿ç­–ã€ç›‘ç®¡ç¯å¢ƒã€è¡¥è´´æƒ…å†µï¼‰
- äº§ä¸šé“¾åœ°ä½ï¼ˆè®®ä»·èƒ½åŠ›ã€ä¾›åº”å•†/å®¢æˆ·é›†ä¸­åº¦ï¼‰
""",
            AnalystModel.MACRO: """
é‡ç‚¹å…³æ³¨ï¼š
- ç»æµå‘¨æœŸä½ç½®ï¼ˆæ‰©å¼ /å³°å€¼/æ”¶ç¼©/è°·åº•ï¼‰
- è´§å¸æ”¿ç­–ï¼ˆåˆ©ç‡ã€å‡†å¤‡é‡‘ç‡ã€æµåŠ¨æ€§ï¼‰
- è´¢æ”¿æ”¿ç­–ï¼ˆåŸºå»ºæŠ•èµ„ã€å‡ç¨ã€äº§ä¸šè¡¥è´´ï¼‰
- é€šèƒ€ç¯å¢ƒï¼ˆCPIã€PPIã€å¯¹æˆæœ¬çš„å½±å“ï¼‰
- æ±‡ç‡é£é™©ï¼ˆè¿›å‡ºå£ã€æµ·å¤–æ”¶å…¥å æ¯”ï¼‰
- åœ°ç¼˜æ”¿æ²»ï¼ˆè´¸æ˜“æ‘©æ“¦ã€ä¾›åº”é“¾å®‰å…¨ï¼‰
""",
            AnalystModel.TECHNICAL: """
é‡ç‚¹å…³æ³¨ï¼š
- ä»·æ ¼è¶‹åŠ¿ï¼ˆé•¿æœŸ/ä¸­æœŸ/çŸ­æœŸè¶‹åŠ¿æ–¹å‘ï¼‰
- æ”¯æ’‘é˜»åŠ›ä½ï¼ˆå…³é”®ä»·ä½ã€çªç ´/è·Œç ´æƒ…å†µï¼‰
- æˆäº¤é‡åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ã€é‡ä»·é…åˆï¼‰
- æŠ€æœ¯æŒ‡æ ‡ï¼ˆå‡çº¿ç³»ç»Ÿã€MACDã€RSIã€KDJã€å¸ƒæ—å¸¦ï¼‰
- å½¢æ€åˆ†æï¼ˆå¤´è‚©é¡¶/åº•ã€åŒåº•ã€ä¸‰è§’å½¢ç­‰ï¼‰
- å¸‚åœºæƒ…ç»ªï¼ˆèµ„é‡‘æµå‘ã€èèµ„ä½™é¢ã€åŒ—å‘èµ„é‡‘ï¼‰
""",
            AnalystModel.RISK: """
é‡ç‚¹å…³æ³¨ï¼š
- æ³¢åŠ¨ç‡åˆ†æï¼ˆå†å²æ³¢åŠ¨ç‡ã€éšå«æ³¢åŠ¨ç‡ã€æ³¢åŠ¨ç‡è¶‹åŠ¿ï¼‰
- å›æ’¤é£é™©ï¼ˆæœ€å¤§å›æ’¤ã€å›æ’¤æ¢å¤æ—¶é—´ï¼‰
- æµåŠ¨æ€§é£é™©ï¼ˆæ—¥å‡æˆäº¤é¢ã€ä¹°å–ä»·å·®ã€å†²å‡»æˆæœ¬ï¼‰
- å°¾éƒ¨é£é™©ï¼ˆé»‘å¤©é¹…äº‹ä»¶ã€æç«¯è¡Œæƒ…è¡¨ç°ï¼‰
- é›†ä¸­åº¦é£é™©ï¼ˆä¸ªè‚¡ä»“ä½ã€è¡Œä¸šé›†ä¸­åº¦ï¼‰
- ç›¸å…³æ€§é£é™©ï¼ˆä¸å¤§ç›˜/è¡Œä¸šçš„ç›¸å…³æ€§ã€åˆ†æ•£åŒ–æ•ˆæœï¼‰
"""
        }
        
        base += specifics.get(model, "")
        
        base += """
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š
{
    "bullish_points": ["çœ‹å¤šç†ç”±1", "çœ‹å¤šç†ç”±2", ...],
    "bearish_points": ["çœ‹ç©ºç†ç”±1", "çœ‹ç©ºç†ç”±2", ...],
    "confidence": 0.0-1.0,
    "bias": "bullish/bearish/neutral",
    "key_factors": ["å…³é”®å› ç´ 1", "å…³é”®å› ç´ 2", ...],
    "reasoning": "ç»¼åˆåˆ†æç†ç”±"
}"""
        
        return base
    
    def conduct_company_research(self, symbol: str, 
                                 quant_data: Dict,
                                 macro_data: Dict) -> Dict:
        """è¿›è¡Œå…¬å¸æ·±åº¦ç ”ç©¶"""
        self._log(f"è¿›è¡Œå…¬å¸æ·±åº¦ç ”ç©¶: {symbol}")
        
        prompt = self._create_company_research_prompt(symbol, quant_data, macro_data)
        response = self.llm.call(prompt, temperature=0.5)
        
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            self._log(f"è§£æå…¬å¸ç ”ç©¶å¤±è´¥: {e}")
        
        return {}
    
    def run_model_analysis(self, model: AnalystModel, symbol: str,
                          company_research: Dict,
                          quant_data: Dict,
                          macro_data: Dict,
                          risk_data: Dict) -> ModelAnalysis:
        """è¿è¡Œå•ä¸ªæ¨¡å‹åˆ†æ"""
        self._log(f"è¿è¡Œ {model.value} åˆ†æ...")
        
        prompt = self._create_model_prompt(model, symbol, company_research,
                                          quant_data, macro_data, risk_data)
        response = self.llm.call(prompt, temperature=0.7)
        
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                
                # æ„å»ºè¾©è®ºè§‚ç‚¹
                bullish_args = [DebateArgument(
                    model=model,
                    side="bullish",
                    points=data.get('bullish_points', []),
                    confidence=data.get('confidence', 0.5)
                )]
                
                bearish_args = [DebateArgument(
                    model=model,
                    side="bearish",
                    points=data.get('bearish_points', []),
                    confidence=1 - data.get('confidence', 0.5)
                )]
                
                return ModelAnalysis(
                    model=model,
                    bullish_arguments=bullish_args,
                    bearish_arguments=bearish_args,
                    overall_bias=data.get('bias', 'neutral'),
                    confidence=data.get('confidence', 0.5),
                    key_factors=data.get('key_factors', []),
                    reasoning=data.get('reasoning', '')
                )
        except Exception as e:
            self._log(f"è§£ææ¨¡å‹åˆ†æå¤±è´¥: {e}")
        
        return ModelAnalysis(model=model, bullish_arguments=[], 
                           bearish_arguments=[], overall_bias="neutral",
                           confidence=0.5, key_factors=[], reasoning="")
    
    def synthesize_decision(self, symbol: str,
                           model_analyses: List[ModelAnalysis],
                           company_research: Dict,
                           quant_data: Dict,
                           macro_data: Dict,
                           risk_data: Dict) -> InvestmentDecision:
        """ç»¼åˆæ‰€æœ‰æ¨¡å‹è§‚ç‚¹ç”ŸæˆæŠ•èµ„å†³ç­–"""
        self._log(f"ç»¼åˆå†³ç­–: {symbol}")
        
        # ç»Ÿè®¡æ¨¡å‹è§‚ç‚¹
        bullish_count = sum(1 for m in model_analyses if m.overall_bias == "bullish")
        bearish_count = sum(1 for m in model_analyses if m.overall_bias == "bearish")
        neutral_count = len(model_analyses) - bullish_count - bearish_count
        
        # è®¡ç®—åŠ æƒç½®ä¿¡åº¦
        avg_confidence = sum(m.confidence for m in model_analyses) / len(model_analyses)
        
        # æ”¶é›†æ‰€æœ‰çœ‹å¤š/çœ‹ç©ºç†ç”±
        all_bullish = []
        all_bearish = []
        for m in model_analyses:
            for arg in m.bullish_arguments:
                all_bullish.extend(arg.points)
            for arg in m.bearish_arguments:
                all_bearish.extend(arg.points)
        
        # ç”Ÿæˆç»¼åˆæç¤ºè¯
        synthesis_prompt = f"""åŸºäºä»¥ä¸‹å¤šæ¨¡å‹åˆ†æç»“æœï¼Œç”Ÿæˆæœ€ç»ˆæŠ•èµ„å†³ç­–ã€‚

ã€è‚¡ç¥¨ã€‘: {symbol}

ã€æ¨¡å‹è§‚ç‚¹ç»Ÿè®¡ã€‘
- çœ‹å¤š: {bullish_count} ä¸ªæ¨¡å‹
- çœ‹ç©º: {bearish_count} ä¸ªæ¨¡å‹
- ä¸­æ€§: {neutral_count} ä¸ªæ¨¡å‹
- å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.2f}

ã€çœ‹å¤šç†ç”±æ±‡æ€»ã€‘
{chr(10).join([f"- {p}" for p in all_bullish[:8]])}

ã€çœ‹ç©ºç†ç”±æ±‡æ€»ã€‘
{chr(10).join([f"- {p}" for p in all_bearish[:8]])}

ã€é‡åŒ–æ•°æ®ã€‘
- é¢„æµ‹æ”¶ç›Š: {quant_data.get('predicted_return', 'N/A')}
- å¤æ™®æ¯”ç‡: {quant_data.get('sharpe_ratio', 'N/A')}

ã€å®è§‚ä¿¡å·ã€‘: {macro_data.get('signal', 'N/A')}
ã€é£é™©ç­‰çº§ã€‘: {risk_data.get('risk_level', 'N/A')}

è¯·ç”ŸæˆæŠ•èµ„å†³ç­–ï¼Œä»¥JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "decision": "å¼ºçƒˆä¹°å…¥/ä¹°å…¥/æŒæœ‰/å–å‡º/å¼ºçƒˆå–å‡º",
    "confidence": 0.0-1.0,
    "position_size": 0.0-1.0,
    "target_price": æ•°å­—æˆ–null,
    "stop_loss": æ•°å­—æˆ–null,
    "time_horizon": "çŸ­æœŸ/ä¸­æœŸ/é•¿æœŸ",
    "logic_chain": ["å†³ç­–é€»è¾‘1", "å†³ç­–é€»è¾‘2", ...],
    "supporting_evidence": ["æ”¯æŒè¯æ®1", ...],
    "opposing_concerns": ["åå¯¹æ‹…å¿§1", ...],
    "risk_mitigation": ["é£é™©ç¼“è§£æªæ–½1", ...]
}}"""
        
        response = self.llm.call(synthesis_prompt, temperature=0.5)
        
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group())
                
                # æ„å»ºæ¨¡å‹å…±è¯†
                model_consensus = {m.model.value: m.overall_bias for m in model_analyses}
                model_confidences = {m.model.value: m.confidence for m in model_analyses}
                
                return InvestmentDecision(
                    symbol=symbol,
                    decision=data.get('decision', 'æŒæœ‰'),
                    confidence=data.get('confidence', 0.5),
                    position_size=data.get('position_size', 0),
                    target_price=data.get('target_price'),
                    stop_loss=data.get('stop_loss'),
                    time_horizon=data.get('time_horizon', 'ä¸­æœŸ'),
                    logic_chain=data.get('logic_chain', []),
                    supporting_evidence=data.get('supporting_evidence', []),
                    opposing_concerns=data.get('opposing_concerns', []),
                    risk_mitigation=data.get('risk_mitigation', []),
                    model_consensus=model_consensus,
                    model_confidences=model_confidences
                )
        except Exception as e:
            self._log(f"è§£æç»¼åˆå†³ç­–å¤±è´¥: {e}")
        
        return InvestmentDecision(symbol=symbol, decision="æŒæœ‰", confidence=0.5, position_size=0)
    
    def conduct_debate(self, symbol: str,
                      quant_data: Dict,
                      macro_data: Dict,
                      risk_data: Dict) -> DebateResult:
        """
        æ‰§è¡Œå®Œæ•´çš„å¤šæ¨¡å‹å¤šç©ºè¾©è®ºæµç¨‹
        """
        self._log("=" * 80)
        self._log(f"å¼€å§‹å¤šæ¨¡å‹å¤šç©ºè¾©è®º: {symbol}")
        self._log("=" * 80)
        
        # 1. å…¬å¸æ·±åº¦ç ”ç©¶
        company_research = self.conduct_company_research(symbol, quant_data, macro_data)
        
        # 2. å¤šæ¨¡å‹åˆ†æ
        model_analyses = []
        for model in AnalystModel:
            analysis = self.run_model_analysis(model, symbol, company_research,
                                              quant_data, macro_data, risk_data)
            model_analyses.append(analysis)
            self._log(f"  {model.value}: {analysis.overall_bias} (ç½®ä¿¡åº¦{analysis.confidence:.0%})")
        
        # 3. ç»¼åˆå†³ç­–
        decision = self.synthesize_decision(symbol, model_analyses, company_research,
                                           quant_data, macro_data, risk_data)
        
        # 4. ç”Ÿæˆè¾©è®ºæ€»ç»“
        debate_summary = self._generate_debate_summary(model_analyses, decision)
        
        # 5. ç»„åˆå»ºè®®
        portfolio_suggestion = {
            "position_size": decision.position_size,
            "target_price": decision.target_price,
            "stop_loss": decision.stop_loss,
            "time_horizon": decision.time_horizon
        }
        
        # 6. é£é™©è¯„ä¼°
        risk_assessment = {
            "risk_level": risk_data.get('risk_level', 'normal'),
            "key_risks": decision.opposing_concerns,
            "mitigation": decision.risk_mitigation
        }
        
        # 7. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report = self._generate_final_report(symbol, company_research,
                                                   model_analyses, decision)
        
        return DebateResult(
            symbol=symbol,
            company_research=company_research,
            model_analyses=model_analyses,
            debate_summary=debate_summary,
            investment_decision=decision,
            portfolio_suggestion=portfolio_suggestion,
            risk_assessment=risk_assessment,
            final_report=final_report
        )
    
    def _generate_debate_summary(self, model_analyses: List[ModelAnalysis],
                                 decision: InvestmentDecision) -> str:
        """ç”Ÿæˆè¾©è®ºæ€»ç»“"""
        lines = []
        lines.append("å¤šæ¨¡å‹è¾©è®ºæ€»ç»“:")
        lines.append("")
        
        for m in model_analyses:
            lines.append(f"ã€{m.model.value}ã€‘")
            lines.append(f"  ç«‹åœº: {m.overall_bias}")
            lines.append(f"  ç½®ä¿¡åº¦: {m.confidence:.0%}")
            lines.append(f"  å…³é”®å› ç´ : {', '.join(m.key_factors)}")
            lines.append("")
        
        lines.append(f"ã€ç»¼åˆå†³ç­–ã€‘")
        lines.append(f"  å»ºè®®: {decision.decision}")
        lines.append(f"  ç½®ä¿¡åº¦: {decision.confidence:.0%}")
        lines.append(f"  å»ºè®®ä»“ä½: {decision.position_size:.0%}")
        
        return "\n".join(lines)
    
    def _generate_final_report(self, symbol: str,
                              company_research: Dict,
                              model_analyses: List[ModelAnalysis],
                              decision: InvestmentDecision) -> str:
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        lines = []
        
        lines.append(f"# æŠ•èµ„å†³ç­–æŠ¥å‘Š: {symbol}")
        lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append("")
        
        # å†³ç­–ç»“è®º
        decision_emoji = {
            "å¼ºçƒˆä¹°å…¥": "ğŸ”¥",
            "ä¹°å…¥": "ğŸŸ¢",
            "æŒæœ‰": "ğŸŸ¡",
            "å–å‡º": "ğŸ”´",
            "å¼ºçƒˆå–å‡º": "â›”"
        }.get(decision.decision, "âšª")
        
        lines.append(f"## {decision_emoji} æŠ•èµ„å†³ç­–: {decision.decision}")
        lines.append(f"- **ç½®ä¿¡åº¦**: {decision.confidence:.0%}")
        lines.append(f"- **å»ºè®®ä»“ä½**: {decision.position_size:.0%}")
        if decision.target_price:
            lines.append(f"- **ç›®æ ‡ä»·**: {decision.target_price:.2f}")
        if decision.stop_loss:
            lines.append(f"- **æ­¢æŸä½**: {decision.stop_loss:.2f}")
        lines.append(f"- **æŠ•èµ„å‘¨æœŸ**: {decision.time_horizon}")
        lines.append("")
        
        # å†³ç­–é€»è¾‘é“¾
        lines.append("## ğŸ§  å†³ç­–é€»è¾‘")
        for i, logic in enumerate(decision.logic_chain, 1):
            lines.append(f"{i}. {logic}")
        lines.append("")
        
        # æ¨¡å‹å…±è¯†
        lines.append("## ğŸ¤– æ¨¡å‹å…±è¯†")
        for model, bias in decision.model_consensus.items():
            emoji = {"bullish": "ğŸŸ¢", "bearish": "ğŸ”´", "neutral": "ğŸŸ¡", "caution": "âš ï¸"}.get(bias, "âšª")
            conf = decision.model_confidences.get(model, 0)
            lines.append(f"- {emoji} **{model}**: {bias} (ç½®ä¿¡åº¦{conf:.0%})")
        lines.append("")
        
        # æ”¯æŒè¯æ®
        lines.append("## âœ… æ”¯æŒè¯æ®")
        for evidence in decision.supporting_evidence[:5]:
            lines.append(f"- {evidence}")
        lines.append("")
        
        # åå¯¹æ‹…å¿§
        lines.append("## âš ï¸ é£é™©ä¸æ‹…å¿§")
        for concern in decision.opposing_concerns[:5]:
            lines.append(f"- {concern}")
        lines.append("")
        
        # é£é™©ç¼“è§£
        lines.append("## ğŸ›¡ï¸ é£é™©ç¼“è§£æªæ–½")
        for mitigation in decision.risk_mitigation:
            lines.append(f"- {mitigation}")
        lines.append("")
        
        # å…¬å¸ç ”ç©¶æ‘˜è¦
        if company_research:
            lines.append("## ğŸ“Š å…¬å¸ç ”ç©¶æ‘˜è¦")
            overview = company_research.get('company_overview', '')
            if overview:
                lines.append(f"**å…¬å¸æ¦‚å†µ**: {overview[:200]}...")
            
            industry = company_research.get('industry', {})
            if industry:
                lines.append(f"**è¡Œä¸š**: {industry.get('lifecycle', '')} | {industry.get('policy_support', '')}")
            
            competition = company_research.get('competition', {})
            if competition:
                lines.append(f"**ç«äº‰åœ°ä½**: å¸‚å ç‡ {competition.get('market_share', 'N/A')}")
            lines.append("")
        
        return "\n".join(lines)


# ==================== æµ‹è¯• ====================

if __name__ == '__main__':
    print("=" * 80)
    print("Multi-Model Debate System - æµ‹è¯•")
    print("=" * 80)
    
    debate_system = MultiModelDebateSystem(verbose=True)
    
    quant_data = {
        "predicted_return": 0.15,
        "predicted_volatility": 0.25,
        "sharpe_ratio": 1.2,
        "factors": ["momentum", "value", "quality"]
    }
    
    macro_data = {"signal": "ğŸŸ¡", "risk_level": "ä¸­é£é™©"}
    risk_data = {"risk_level": "normal", "volatility": 0.25}
    
    result = debate_system.conduct_debate(
        symbol="AAPL",
        quant_data=quant_data,
        macro_data=macro_data,
        risk_data=risk_data
    )
    
    print("\n" + "=" * 80)
    print("æœ€ç»ˆæŠ¥å‘Š")
    print("=" * 80)
    print(result.final_report)
